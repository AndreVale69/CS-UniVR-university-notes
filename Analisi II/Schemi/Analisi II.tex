\documentclass[a4paper]{article}
\usepackage[italian]{babel}
\usepackage[italian]{isodate}  		% formato delle date in italiano
\usepackage{graphicx}				% gestione delle immagini
\usepackage{amsfonts}
\usepackage{booktabs}				% tabelle di qualità superiore
\usepackage{amsmath}				% pacchetto matematica
\usepackage{cancel}					% per barrare le equazioni (semplificazioni)
\usepackage{mathtools}				% per sottolineare sotto le equazioni
\usepackage{enumitem}				% gestione delle liste
\usepackage{pifont}					% pacchetto con elenchi carini
\usepackage[x11names]{xcolor}		% colori aggiuntivi
% Link ipertestuali per l'indice
\usepackage{xcolor}
\usepackage[linkcolor=black, citecolor=blue, urlcolor=cyan]{hyperref}
\hypersetup{
	colorlinks=true
}

%\usepackage{showframe}				% visualizzazione bordi
%\usepackage{showkeys}				% visualizzazione etichetta

\newtheorem{theorem}{Teorema}
\newcommand{\dquotes}[1]{``#1''}

\begin{document}
	\author{VR443470}
	\title{Analisi II}
	\date{\printdayoff\today}
	\maketitle
	
	\newpage
	
	% indice
	\tableofcontents
	
	\newpage
	
	%%%%%%%%%%%%%%
	% LEZIONE 01 %
	%%%%%%%%%%%%%%
	\section{Lezione 01}
	
	\subsection{Equazioni a variabili separabili}\label{Equazioni a variabili separabili}
	
	Le equazioni differenziali a \textbf{variabili separabili} hanno due forme:
	
	\begin{itemize}
		\item \textbf{Forma canonica.} $y'(x) = f(x)\cdot g\left(y(x)\right)$
		\item \textbf{Forma alternativa.} $y' = f(x) \cdot g(y)$
	\end{itemize}
	
	\noindent
	Dove $f$ e $g$ sono funzioni continue ``in un intervallo reale'', più formalmente:
	
	\begin{gather*}
		f \text{ continua in } I \subseteq R \\
		g \text{ continua in } J \subseteq R
	\end{gather*}
	
	\noindent
	Le \textcolor{Red3}{\textbf{soluzioni}} di un'equazione differenziale possono essere:
	
	\begin{itemize}
		\item[\ding{51}] \textbf{Costanti.} Quando $\bar{y}\in\mathbb{R}$ è uno zero di $g(y)$ e dunque vale:
		\begin{equation*}
			y(x)=\bar{y} \hspace{1em} \forall x\in I
		\end{equation*}

		\noindent
		Quindi, quando un valore annulla $g(y)$, vuol dire che è stata trovata una soluzione costante dell'equazione differenziale.
		
		\item[\ding{51}] \textbf{\underline{Non} costanti.} Quando $g(y)$ non si annulla e quindi ci sarà la relazione:
		\begin{equation*}
			y'(x) = f(x) \cdot g(y(x)) \longrightarrow \dfrac{y'(x)}{g(y(x))} = f(x)
		\end{equation*}
	\end{itemize}

	\noindent
	Tuttavia, supponendo che $G(y)$ sia una primitiva di $\dfrac{1}{g(y)}$, allora:
	
	\begin{equation*}
		\dfrac{\mathrm{d}}{\mathrm{d}x} G\left(y(x)\right) = f(x) \hspace{2em} \text{con} \hspace{2em} G(x) = F(x) + c \hspace{1em} c\in\mathbb{R}
	\end{equation*}
	
	\noindent
	Dove $F(x)$ è la primitiva di $f(x)$. Ma dato che $G$ è invertibile, si scrive:
	
	\begin{equation}\label{integrale_generale}
		y(x) = G^{-1} \left(F(x) + c\right) \hspace{2em} \text{con } c \in \mathbb{R}
	\end{equation}

	\noindent
	L'equazione \ref{integrale_generale} rappresenta l'\textbf{insieme delle soluzioni dell'equazione differenziale} e viene chiamato anche \textcolor{Red3}{\textbf{integrale generale}}.
	
	\newpage
	
	\begin{center}
		\large \textcolor{Green4}{\textbf{Esempio equazione differenziale a variabili separabili}}
	\end{center}
	
	\noindent
	Equazione differenziale: $y' = x y$ in cui la $x$ rappresenta $f(x)$ e la $y$ rappresenta la $g(y)$. Una \textbf{nuova notazione} utilizzata negli esercizi è la seguente:
	
	\begin{equation*}
		f, g \in \mathcal{C}^{0}(\mathbb{R})
	\end{equation*}

	\noindent
	Che indica che le \textbf{funzioni $f$ e $g$ sono continue nell'intervallo $\mathbb{R}$}.
	
	L'esercizio si svolge \emph{cercando} inizialmente le \underline{soluzioni costanti}. Il modo più semplice per farlo è porre $y=0$ e verificare se $g(y)$ si annulla: in caso affermativo esiste una soluzione costante. In questo esercizio si annulla, quindi \emph{ha soluzione costante}.
	
	Al contrario, le \underline{soluzioni \emph{non} costanti} si trovano quando $y \ne 0$. Quindi:
	
	\begin{gather*}
		y' = xy \rightarrow \dfrac{\mathrm{d}y}{\mathrm{d}x} = xy \rightarrow \dfrac{1}{y} \mathrm{d}y = x \: \mathrm{d}x \rightarrow \displaystyle \int \dfrac{1}{y} \mathrm{d}y = \int x \mathrm{d} x \rightarrow \ln |y| = \dfrac{1}{2} x^{2} + c \hspace{1em} c\in\mathbb{R}
	\end{gather*}

	\noindent
	Esplicitando il risultato:
	
	\begin{equation*}
		|y(x)| = e^{\frac{1}{2} x^2 + c} \hspace{1em} c\in\mathbb{R} \longrightarrow y(x) = \pm e^{c} \cdot e^{\frac{1}{2} x^2} \hspace{1em} c \in \mathbb{R}
	\end{equation*}

	Dato che $e^c$ può essere positivo o negativo escluso lo zero (soluzione costante!), si riscrive più precisamente l'\textbf{integrale generale dell'equazione}:
	
	\begin{equation*}
		y(x) = k \cdot e^{\frac{1}{2} x^2} \hspace{1em} k \in \mathbb{R} \setminus \{0\}
	\end{equation*}

	È possibile \textbf{verificare la soluzione} dell'equazione differenziale effettuando una derivazione:
	
	\begin{gather*}
		y(x) = k \cdot e^{\frac{1}{2} x^2} \\
		y'(x) = k \cdot x \cdot e^{\frac{1}{2} x^2} \hspace{1em} \forall x \in \mathbb{R} \hspace{1em} \text{\textcolor{Green3}{\checkmark Verificata}}
	\end{gather*}
	
	\newpage
	
	\subsection{Problema di Cauchy}
	
	Nel caso in cui si è interessati ad una soluzione particolare, è necessaria una condizione. In questo caso, si è di fronte al \textcolor{Red3}{\textbf{problema di Cauchy}}, il quale è caratterizzato dalla presenza di un'equazione differenziale e da \underline{almeno} una condizione.\newline
	L'\textbf{obbiettivo} è \underline{verificare} la/le condizione/i tramite una soluzione (o più soluzioni).\newline
	La \textbf{struttura} è la seguente:
	
	\begin{equation}\label{problema_di_Cauchy}
		\begin{cases}
			y'= f(x) \cdot g(y) \\
			y(x_0) = y_0 & x_0 \in I
		\end{cases}
	\end{equation}

	\vspace{1em}

	\begin{center}
		\large \textcolor{Green4}{\textbf{Esempio problema di Cauchy}}
	\end{center}

	\noindent
	Il problema:
	
	\begin{equation*}
		\begin{cases}
			y' = -3y \\
			y(0) = 2
		\end{cases}
	\end{equation*}

	\noindent
	La risoluzione:
	
	\begin{gather*}
		\dfrac{\mathrm{d}y}{\mathrm{d}x} = - 3y \longrightarrow \dfrac{\mathrm{d}y}{y} = - 3 \: \mathrm{d}x \longrightarrow  \displaystyle \int {\dfrac{1}{y} \: \mathrm{d}y} = -3x + c \longrightarrow ...\\
		... \longrightarrow y(x) = k e^{-3x} \hspace{1em} k \in \mathbb{R} \text{ [}\textcolor{Red3}{\textbf{Integrale generale}}\text{]}
	\end{gather*}

	\noindent
	Adesso si esegue la \textbf{verifica della condizione} sostituendo quest'ultima nella soluzione:
	
	\begin{gather*}
		\text{Condizione: } y(0) = 2 \\
		\text{Eq. diff.: } y(0) = k e^{-3 \cdot (0)} \longrightarrow 2 = k \cdot e^0 \longrightarrow k = 2
	\end{gather*}

	\noindent
	Quindi, la \textbf{soluzione del problema di Cauchy}:
	
	\begin{equation*}
		y(x) = 2 e^{-3x} \hspace{1em} \text{con } x \in \mathbb{R}
	\end{equation*}

	\newpage
	
	\begin{center}
		\large \textcolor{Green4}{\textbf{Un altro esempio del problema di Cauchy}}
	\end{center}

	\noindent
	Il problema:
	
	\begin{equation*}
		\begin{cases}
			y' = (1 + y^2) x & f, g \in \mathcal{C}^0 \left(\mathbb{R}\right) \\
			y(0) = 1
		\end{cases}
	\end{equation*}

	\noindent
	Cercando la \textbf{soluzione costante} sostituendo $y = 0$, si osserva che la funzione non si annulla, quindi $1 + y^2 \ne 0 \hspace{1em} \forall y \in \mathbb{R}$, ovvero nessun numero reale annulla $g(y)$.
	
	\noindent
	Cercando eventuali \textbf{soluzioni costanti}:
	
	\begin{gather*}
		\dfrac{\mathrm{d}y}{\mathrm{d}x} = (1 + y^2) x \longrightarrow \dfrac{1}{1 + y^2} \mathrm{d}y = x \mathrm{d}x \longrightarrow \int{\dfrac{1}{1 + y^2} \mathrm{d}y} = \int{x \mathrm{d}x} \longrightarrow \\
		\longrightarrow \textcolor{Red3}{\textbf{ Integrale generale}}\text{: } \arctan{\left(y\right)} = \dfrac{1}{2} x^2 + c \hspace{1em} c \in \mathbb{R}
	\end{gather*}

	\noindent
	\textbf{Verificando la condizione} sostituendo, si ottiene:
	
	\begin{gather*}
		\text{Condizione: } y(0) = 1 \\
		\text{Eq. diff.: } \arctan{\left(1\right)} = \dfrac{1}{2}\cdot 0^2 + c \longrightarrow \arctan{\left(1\right)} = 0 + c \longrightarrow c = \dfrac{\pi}{4}
	\end{gather*}
	
	\noindent
	È possibile \textbf{esplicitare} la funzione $y(x)$ dall'integrale generale, ottenendo la seguente forma:
	
	\begin{equation*}
		y(x) = \tan{\left(\dfrac{1}{2}x^2 + \dfrac{\pi}{4}\right)}
	\end{equation*}

	\noindent
	Inoltre, dato che $\arctan$ è sicuramente compreso, per definizione, nell'intervallo:
	
	\begin{equation*}
		\pm \dfrac{\pi}{2} \longrightarrow -\dfrac{\pi}{2} < \dfrac{1}{2} x^2 + c < \dfrac{\pi}{2}
	\end{equation*}

	\noindent
	Allora è possibile sostituire la $c$ con il valore trovato durante l'esplicitazione:s
	
	\begin{equation*}
		-\dfrac{\pi}{2} < \dfrac{1}{2} x^2 + \dfrac{\pi}{4} < \dfrac{\pi}{2}
	\end{equation*}

	\noindent
	Per controllare che la soluzione sia effettivamente all'\textbf{interno dell'intervallo}, avviene nel seguente modo:
	
	\begin{equation*}
		-\dfrac{\pi}{2} < \dfrac{1}{2} x^2 + \dfrac{\pi}{4} < + \dfrac{\pi}{2}
	\end{equation*}

	\noindent
	Sicuramente $-\dfrac{\pi}{2} < \dfrac{1}{2} x^2 + \dfrac{\pi}{4}$ è verificata per $x \in \mathbb{R}$. La parte di destra è possibile verificarla effettuando qualche manipolazione sulla disuguaglianza:
	
	\begin{equation*}
		\dfrac{1}{2} x^2 + \dfrac{\pi}{4} < + \dfrac{\pi}{2} \longrightarrow \dfrac{1}{2} x^2 < \dfrac{\pi}{2} - \dfrac{\pi}{4} \longrightarrow \dfrac{1}{2} x^2 < \dfrac{\pi}{4} \longrightarrow x^2 < \dfrac{\pi}{2}
	\end{equation*}

	\noindent
	Quindi, la soluzione è corretta quando $x$ è nell'intervallo (esplicitando):
	
	\begin{equation*}
		- \sqrt{\dfrac{\pi}{2}} < x < + \sqrt{\dfrac{\pi}{2}}
	\end{equation*}

	\newpage

	\noindent
	Quindi, l'\textcolor{Red3}{\textbf{intervallo massimale delle soluzioni}}, ovvero il più grande intervallo in cui è definita la soluzione del problema di Cauchy, è così definita:
	
	\begin{figure}[!htp]
		\centering
		\includegraphics[width=0.7\textwidth]{img/intervallo_max_eg.pdf}
		\caption{Intervallo massimale delle soluzioni.}
	\end{figure}

	\newpage

	%%%%%%%%%%%%%%
	% LEZIONE 02 %
	%%%%%%%%%%%%%%
	\section{Lezione 02}
	
	\subsection[Problema di Cauchy per eq. diff. a variabili separabili]{Problema di Cauchy per equazioni differenziali a variabili separabili}
	
	Per introdurre il problema di Cauchy con le equazioni differenziali a variabili separabili, è necessario introdurre il \textbf{teorema di \underline{esistenza} e \underline{unicità}}.\newline
	
	\noindent
	Si consideri il problema:
	
	\begin{equation*}
		\begin{cases}
			y^{'} = f\left(x\right) \cdot g\left(y\right) \\
			y\left(x_{0}\right) = y_{0}
		\end{cases}
	\end{equation*}

	\noindent
	In cui $f$ è una funzione continua su $I = \left(x_{0} - r_{1}, x_{0} + r_{1}\right)$ e $g$ è una funzione continua su un intervallo $J = \left(y_{0} - r_{2}, y_{0} + r_{2}\right)$.
	
	\begin{theorem}[Esistenza]\label{teorema esistenza}
		Esiste una soluzione al problema di Cauchy definita per ogni $x \in I^{'} = \left[x_{0} - \delta, x + \delta\right] \subseteq I$. È dunque \textbf{garantita la soluzione locale} e non obbligatoriamente su tutto l'intervallo $I$.
	\end{theorem}

	\begin{theorem}[Unicità]\label{teorema unicità}
		Se $g\left(y\right)$ è \underline{continua e derivabile} con derivata continua (formalmente: $g\left(y\right) \in \mathcal{C}^{1} \left(J\right)$), allora la \textbf{soluzione è unica}.
	\end{theorem}

	\begin{figure}[!htp]
		\centering
		\includegraphics[width=0.8\textwidth]{img/prob_cauchy-variabili_separabili.pdf}
		\caption{Rappresentazione grafica del problema di Cauchy con variabili separabili.}
	\end{figure}

	\newpage

	\noindent
	\textbf{Caso in cui il teorema dell'unicità viene violato! È facilmente riconoscibile poiché ci sono due soluzioni che passano per la condizione imposta $\left(\text{il punto } x_{0}, y_{0}\right)$.}
	
	\begin{figure}[!htp]
		\centering
		\includegraphics[width=0.8\textwidth]{img/prob_cauchy-variabili_separabili_violazione.pdf}
		\caption{Teorema dell'esistenza garantito, ma teorema dell'unicità violato.}
	\end{figure}

	\newpage
	
	\subsection{Esempi di problemi di Cauchy}
	
	\subsubsection[Esempio semplice]{\textcolor{Green4}{\textbf{Esempio semplice}}}
	
	\noindent
	Il problema:
	
	\begin{equation*}
		\begin{cases}
			y' \cdot y = 1 \\
			y\left(1\right) = 0
		\end{cases}
	\end{equation*}
	
	\noindent
	In questo caso \textbf{\underline{non esiste una soluzione}} poiché $y^{'}\left(1\right) \cdot y\left(1\right)$ deve essere uguale a $1$. Se nell'espressione $y^{'}\left(1\right) \cdot y\left(1\right) = 1$ vengono sostituite le funzioni con il valore zero, risulta impossibile l'uguaglianza: $y^{'}\left(1\right) \cdot 0 = 1$.\newline
	
	\subsubsection[Esempio medio]{\textcolor{Green4}{\textbf{Esempio medio}}}
	
	\noindent
	Il problema:
	
	\begin{equation*}
		\begin{cases}
			y' = y^{\frac{2}{3}} \\
			y\left(0\right) = 0
		\end{cases}
	\end{equation*}
	
	\noindent
	Esiste sicuramente \textbf{\underline{una soluzione costante}} con $y = 0$.
	
	Inoltre, andando a studiare le \textbf{\underline{soluzioni non costanti}}, quindi con $y \ne 0$, si evince chiaramente che:
	
	\begin{gather*}
		y^{'} = y^{\frac{2}{3}} \longrightarrow
		\dfrac{\mathrm{d}y}{y^{\frac{2}{3}}} = \mathrm{d}x \longrightarrow
		y^{-\frac{2}{3}} \mathrm{d}y = \mathrm{d}x \\
		\textbf{Integrando...} \longrightarrow
		3y^{\frac{1}{3}} = x + c
	\end{gather*}

	\noindent
	Dato che utilizzando la condizione del problema $y\left(0\right) = 0$ la $c$ è zero:
	
	\begin{equation*}
		3\left(y\left(0\right)^{\frac{1}{3}}\right) = 0 + c
	\end{equation*}

	\noindent
	Esplicitando la $y$, si ottiene la \textbf{soluzione al problema di Cauchy}:
	
	\begin{equation*}
		y = \dfrac{1}{27} x^{3} \hspace{2em} \text{con } x \ge 0
	\end{equation*}

	\newpage

	\noindent\fbox{%
		\parbox{\textwidth}{%
			È interessante notare che la soluzione può essere prolungata a tutto l'insieme dei reali $\mathbb{R}$:
			
			\begin{equation*}
				\tilde{y}\left(x\right) = 
				\begin{cases}
					0 					& x < 0 \\
					\dfrac{1}{27} x^{3} & x \ge 0
				\end{cases}
			\end{equation*}
		
			\noindent
			Inoltre, è possibile anche traslare funzioni di questo tipo:
			
			\begin{equation*}
				\tilde{y}\left(x\right) = 
				\begin{cases}
					0 & x < \alpha \\
					\dfrac{1}{27} \left(x - \alpha\right)^{3} & x \ge \alpha
				\end{cases}
			\end{equation*}
			
			\noindent
			Questo dimostra che la funzione ha una derivata non limitata nell'intervallo.
		}%
	}

	\begin{figure}[!htp]
		\centering
		\includegraphics[width=0.6\textwidth]{img/prob_cauchy-variabili_separabili-OSS.pdf}
		\caption{Grafico dell'osservazione estesa a $\mathbb{R}$.}
		\includegraphics[width=0.6\textwidth]{img/prob_cauchy-variabili_separabili-OSS2.pdf}
		\caption{Grafico dell'osservazione estesa a $\mathbb{R}$ e traslata di $\alpha$.}
	\end{figure}

	\newpage
	
	\subsubsection[Esempio difficile]{\textcolor{Green4}{\textbf{Esempio difficile}}}
	
	\noindent
	Il problema:
	
	\begin{equation*}
		\begin{cases}
			e^{x+y} \cdot y + x = 0 \\
			y\left(0\right) = 0
		\end{cases}
	\end{equation*}
	
	\noindent
	Tuttavia, la funzione non è in forma canonica, quindi si eseguono alcune operazioni algebriche:
	
	\begin{equation*}
		e^{x+y} \cdot y + x = 0 \longrightarrow e^{x+y} \cdot y = -x \longrightarrow y^{'} = - \dfrac{x}{e^{x+y}}
	\end{equation*}

	\noindent
	Quindi:
	
	\begin{equation*}
		\begin{cases}
			y^{'} = - \dfrac{x}{e^{x+y}} \\
			y\left(0\right) = 0
		\end{cases}
	\end{equation*}

	\noindent
	Il problema si risolve tramite la \textbf{\underline{tecnica delle variabili separabili}}. Infatti:
	\begin{equation*}
		y^{'} = -\dfrac{x}{e^{x+y}}; \hspace{1em}
		y^{'} = -\dfrac{x}{e^{x} \cdot e^{y}}; \hspace{1em}
		y^{'} = -\dfrac{x}{e^{x}} \cdot \dfrac{1}{e^{y}}; \hspace{1em}
		y^{'} = - \underbracket[0.14ex]{x \cdot e^{-x}}_{f\left(x\right)} \cdot \underbracket[0.14ex]{e^{-y}}_{g\left(y\right)}
	\end{equation*}

	\noindent
	Con gli intervalli definiti in tutto $\mathbb{R}$ cioè $I = J = \mathbb{R}$.
	
	\noindent
	La risoluzione si svolge separando le variabili e integrando (N.B. la funzione $g\left(y\right)$ non ha zeri e quindi \textbf{\underline{non esistono soluzioni costanti}}):
	
	\begin{gather*}
		e^{y} \mathrm{d}y = -x e^{-x} \mathrm{d}x; \hspace{1em}
		\int e^{y} \mathrm{d}y = \int -x e{-x} \mathrm{d}x; \hspace{1em}
		e^{y} = x e^{-x} - \int 1 \cdot e^{-x} \mathrm{d}x; \hspace{1em} \\
		\textbf{Soluzione: } e^{y} = x e^{-x} + e^{-x} + c
	\end{gather*}

	\noindent
	Dunque, l'\textbf{\underline{integrale generale}}:
	
	\begin{equation*}
		y\left(x\right) = \ln \left(x e^{-x} + e^{-x} + c\right)
	\end{equation*}

	\noindent
	Imponendo la \textbf{condizione iniziale}:
	
	\begin{equation*}
		y\left(0\right) = \ln \left(1+c\right) \hspace{2em} \text{con } c = 0
	\end{equation*}

	\noindent
	Per cui, la \textbf{\underline{soluzione al problema di Cauchy}} è:
	
	\begin{equation*}
		y\left(x\right) = \ln\left(x e^{-x} + e^{-x}\right) \hspace{2em} \text{con } x > -1
	\end{equation*}

	\noindent
	L'\textbf{\underline{intervallo massimale}} è:
	
	\begin{equation*}
		\left(-1; +\infty\right)
	\end{equation*}

	\newpage
	
	\subsection{Modello di crescita logaritmica}
	
	Creato dal matematico belga Verhulst, riguarda le equazioni differenziali. Infatti, la forma generale trovata nei problemi di Cauchy è del tipo $y^{'} = a y \left(1 - by\right)$, ma in questo modello è importante una forma alternativa della funzione del problema di Cauchy:
	
	\begin{equation*}
		\begin{cases}
			\text{Funzione:} & y^{'} = k y \left(1 - y\right) \\
			\text{Condizione:} & y\left(0\right) = y_{0}
		\end{cases}
	\end{equation*}

	\noindent
	In modo più formale, nel modello di crescita logaritmica l'equazione differenziale rappresenta una frazione di popolazione. Dunque, è possibile riscriverla come:
	
	\begin{equation*}
		\begin{cases}
			y^{'} = k y\left(1 - y\right) & 0 \le y \le 1 \\
			y\left(0\right) = y_{0} & \text{altrimenti}
		\end{cases}
	\end{equation*}

	\noindent
	In questo caso, le \textbf{\underline{soluzioni costanti} (o stabili, o d'equilibrio)} sono $y = 0$ e $y = 1$. Invece, le \textbf{\underline{soluzioni \emph{non} costanti}} sono:
	
	\begin{gather*}
		\dfrac{\mathrm{d}y}{y\left(1 - y\right)} = k \mathrm{d}x \xlongrightarrow{\text{Integrando...}}
		\int \dfrac{\mathrm{d}y}{y\left(1 - y\right)} = \int k \mathrm{d}x; \\
		\ln\left(y\right) - \ln\left(1 - y\right) = k x + c; \\
		\ln\left(\dfrac{y}{1 - y}\right) = k x + c
	\end{gather*}

	\noindent
	Nonostante la forma sia corretta, è utile avere la $y$ esplicitata, quindi:
	
	\begin{gather*}
		\begin{matrix}
			\dfrac{y}{1 - y} = e^{kx} \cdot e^{c}; & y = e^{c} \cdot e^{kx} \cdot \left(1 - y\right); \\
			\\
			y = e^{c} \cdot e^{kx} - e^{c} \cdot e^{kx} y; & y\left(1 + e^{c} \cdot e^{kx}\right) = e^{c} \cdot e^{kx}; \\
			\\
			y\left(x\right) = \dfrac{e^{c} \cdot e^{kx}}{1 + e^{c} \cdot e^{kx}}
		\end{matrix}
	\end{gather*}

	\noindent
	Il modello si conclude \textbf{\underline{applicando}} la \textbf{\underline{condizione iniziale}}:
	
	\begin{gather*}
		\underbracket[0.14ex]{y\left(0\right)}_{=y_{0}} = \dfrac{e^{c}}{1 + e^{c}} \xlongrightarrow{\text{Esplicitando } e^{c}}
		\left(1 + e^{c}\right) y_{0} = e^{c}; \hspace{2em} e^{c} \left(y_{0} + 1\right) = y_{0}; \\
		e^{c} = \dfrac{y_{0}}{1 - y_{0}}
	\end{gather*}

	\newpage
	\noindent
	Quindi, andando a sostituire il valore trovato con la condizione iniziale, si trova la \textbf{\underline{soluzione}}:
	
	\begin{equation*}
		y\left(t\right) = \dfrac{\dfrac{y_{0}}{1 - y_{0}} \cdot e^{kx}}{1 + \dfrac{y_{0}}{1 - y_{0}} \cdot e^{kx}} = \dfrac{y_{0} \cdot e^{kx}}{1 - y_{0} + y_{0} \cdot e^{kx}}
	\end{equation*}

	\begin{figure}[!htp]
		\centering
		\includegraphics[width=0.7\textwidth]{img/modello_crescita_logaritmica-eg.pdf}
		\caption{Esempio di grafico con un certo $y_{0}$.}
	\end{figure}

	\newpage
	
	\subsection{Esercizio con domande da \textcolor{Red3}{esame}}
	
	Dato il seguente problema di Cauchy:
	
	\begin{equation*}
		\begin{cases}
			y^{'} = e^{x} + y^{2} \\
			y\left(0\right) = 1
		\end{cases}
	\end{equation*}

	\noindent
	Si \textbf{risponda alle seguenti \underline{domande}}:
	
	\begin{enumerate}[label=\Roman*]
		\item Scrivere l'equazione della tangente al grafico della curva con soluzione nel punto di coordinate $\left(0, 1\right)$.
		
		\item Vicino (o intorno) al punto $x = 0$, la funzione è concava o convessa?
	\end{enumerate}
	
	\noindent
	\textcolor{Green4}{\textbf{\underline{Risposta domanda I.}}}\newline
	
	\noindent
	L'equazione generale (o definizione) della retta tangente è:
	
	\begin{equation*}
		y - y_{0} = m \left(x - x_{0}\right)
	\end{equation*}

	\noindent
	Con $x_{0}$, $y_{0}$ che sono coordinate del punto $m$, ovvero la \emph{pendenza}. Quindi, andando a sostituire le coordinate fornite dall'esercizio nella definizione di retta tangente:
	
	\begin{equation*}
		\textbf{Sostituzione } \left(0, 1\right) \rightarrow y - 1 = m \left(x - 0\right)
	\end{equation*}

	\noindent
	Sapendo che la pendenza $m$ è la derivata della funzione calcolata nel punto zero, si eseguono questi calcoli usando la funzione fornita dall'esercizio:
	
	\begin{equation*}
		m \longrightarrow y^{'}\left(0\right) = e^{0} + \left[y\left(0\right)\right]^{2}; \hspace{2em} y^{'}\left(0\right) = 1 + 1^{2} = 2
	\end{equation*}

	\noindent
	Il valore noto viene sostituito nella definizione di retta tangente, quindi l'equazione di quest'ultima diventa:
	
	\begin{equation*}
		y - 1 = 2\left(x - 0\right) \longrightarrow y = 2x - 1
	\end{equation*}\newline
	
	\noindent
	\textcolor{Green4}{\textbf{\underline{Risposta domanda II.}}}\newline
	
	\noindent
	Per la concavità o convessità si studia la derivata seconda:
	
	\begin{equation*}
		y^{''}\left(x\right) = e^{x} + 2y\left(x\right) \cdot y^{'}\left(x\right)
	\end{equation*}

	\noindent
	Dalla derivata seconda ottenuta si inserisce la condizione del problema:
	
	\begin{equation*}
		y^{''}\left(0\right) = 1 + 2 \cdot 1 \cdot \textcolor{Red3}{2} = 5
	\end{equation*}

	\noindent
	Il \textcolor{Red3}{2} è il risultato della $y^{'}\left(0\right)$ trovato prima.
	
	Dato che il \textbf{\underline{risultato è positivo, allora la funzione è convessa}}. Più formalmente, in un intorno di $x = 0$, se la $y^{''}\left(0\right) > 0$, la funzione si dice che è convessa.
	
	\section{Lezione 03}
	
	\subsection{Equazioni differenziali del primo ordine}
	
	La forma generale di un'equazione differenziale lineare del \textbf{\underline{primo ordine}} è la seguente:
	
	\begin{equation*}
		y^{'} + a\left(x\right) y = f\left(x\right) \hspace{2em} \text{con } a\left(x\right), f\left(x\right) \in \mathcal{C}^{0}\left(I\right)
	\end{equation*}

	\noindent
	Si ricorda che la $I$ indica l'intervallo nell'insieme dei numeri naturali $\mathbb{R}$. Inoltre, l'\textbf{equazione} si dice:
	
	\begin{itemize}
		\item \textcolor{Red3}{\textbf{\underline{Omogenea}}}, se $f\left(x\right) \equiv 0$, cioè è nulla;
		\item \textcolor{Red3}{\textbf{\underline{Non omogenea}}}, se $f\left(x\right) \not\equiv 0$, cioè non nulla;
	\end{itemize}

	\noindent
	La \textbf{\underline{risoluzione}} di queste equazioni prevede due passaggi:
	
	\begin{enumerate}
		\item Determinare una primitiva $A\left(x\right)$ di $a\left(x\right)$ sull'intervallo dei reali $I$ e considerare la funzione $e^{A\left(x\right)}$;
		
		\item Moltiplicare entrambi i membri dell'equazione differenziale per $e^{A\left(x\right)}$, chiamato anche \textcolor{Red3}{\textbf{\underline{fattore integrante}}}.
	\end{enumerate}

	\noindent
	L'\textcolor{Red3}{\textbf{\underline{obbiettivo}}} finale, ovvero successivamente alla risoluzione, è avere al primo membro la derivata di un prodotto tra funzioni.\newline
	
	\noindent
	Più esplicitamente, in maniera \textbf{generalistica}, si eseguono i seguenti passaggi:
	
	\begin{enumerate}
		\item $\overbrace{e^{A\left(x\right)} \cdot y^{'}\left(x\right) + e^{A\left(x\right)} \cdot a\left(x\right) \cdot y\left(x\right)}^{\text{Derivata di un prodotto tra due funzioni}} = e^{A\left(x\right)} \cdot f\left(x\right) \hspace{2em} \forall x \in I$

		\item $e^{A\left(x\right)} \cdot y\left(x\right) = \int e^{A\left(x\right)} f\left(x\right) \: \mathrm{d}x \hspace{2em} \text{con } c \in \mathbb{R}$
	\end{enumerate}

	\noindent
	Per derivata di un prodotto tra due funzioni ovviamente si intende:
	
	\begin{equation*}
		\left(e^{A\left(x\right)} \cdot y\left(x\right)\right)^{'}
	\end{equation*}

	\noindent
	La \textcolor{Red3}{\textbf{\underline{forma risolutiva generale}}} è la seguente:
	
	\begin{equation*}
		y\left(x\right) = e^{-A\left(x\right)} \left(\int e^{A\left(x\right)} f\left(x\right) \: \mathrm{d}x + c\right)
	\end{equation*}

	\noindent
	Ovviamente, per determinare la costante $c$ si utilizzano le condizioni iniziali.
	
	\newpage
	
	\noindent
	Combinando l'equazione differenziale lineare del primo ordine con le condizioni iniziali, il sistema da risolvere è il di nuovo il \textcolor{Red3}{\textbf{\underline{problema di Cauchy}}}:
	
	\begin{equation*}
		\begin{cases}
			y^{'}\left(x\right) + a\left(x\right) \cdot y\left(x\right) = f\left(x\right)	& a\left(x\right), f\left(x\right) \in \mathcal{C}^{0}\left(I\right) \\
			y\left(x_{0}\right) = y_{0}														& x_{0}, y_{0} \in I
		\end{cases}
	\end{equation*}

	\noindent
	E per definizione del teorema dell'esistenza e dell'unicità (teoremi \ref{teorema esistenza} e \ref{teorema unicità} a pagina \pageref{teorema esistenza}), l'equazione differenziale lineare del primo ordine \textbf{\underline{ammette un'unica soluzione}} \textbf{\underline{di classe}} $\mathcal{C}^{1}\left(I\right)$. Si osservi che la soluzione è definita su \emph{tutto} l'intervallo e di conseguenza è una \textbf{\underline{soluzione globale}}!\newline
	
	\noindent
	Nei prossimi paragrafi vengono presentati degli esempi guidati.
	
	\newpage
	
	\subsubsection[Esempio 1]{\textcolor{Green4}{\textbf{Esempio 1}}}
	
	L'equazione differenziale è la seguente:
	
	\begin{equation*}
		y^{'} + 2xy = x
	\end{equation*}

	\noindent
	Si osservi che l'equazione differenziale, oltre ad essere risolvibile tramite la tecnica presentata nel paragrafo precedente, è possibile risolverla anche a \emph{variabili separabili} (paragrafo \ref{Equazioni a variabili separabili}). In quest'ultimo caso, l'equazione sarebbe:
	
	\begin{equation*}
		y^{'} = x\left(1-2y\right)
	\end{equation*}

	\noindent
	Tuttavia, si ricerca l'integrale generale come spiegato nel metodo nel paragrafo precedente.\newline
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 1}}}\newline
	
	\noindent
	Data la  forma generale dell'equazione differenziale lineare del primo ordine:
	
	\begin{equation*}
		y^{'} + a\left(x\right) y = f\left(x\right)
	\end{equation*}

	\noindent
	Dall'equazione dell'esercizio si ottiene:
	
	\begin{equation*}
		\begin{array}{lll}
			y^{'} + 2xy = x & \longrightarrow	& a\left(x\right) = 2x \\
							& \longrightarrow	& f\left(x\right) = x
		\end{array}
	\end{equation*}

	\noindent
	Con entrambe le funzioni $a\left(x\right)$ e $f\left(x\right)$ continue sull'insieme dei reali $\mathbb{R}$.\newline
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 2}}}\newline
	
	\noindent
	Si calcola la primitiva del fattore $a\left(x\right)$:
	
	\begin{equation*}
		a\left(x\right) = 2x \xrightarrow{\text{primitiva}} A\left(x\right) = x^{2}
	\end{equation*}

	\noindent
	Così da costruire la funzione $e^{A\left(x\right)}$:
	
	\begin{equation*}
		e^{A\left(x\right)} \xrightarrow{\text{sostituzione}} e^{x^{2}}
	\end{equation*}

	\noindent
	Funzione chiamata anche \textbf{\underline{fattore integrante}}.\newline
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 3}}}\newline
	
	\noindent
	Grazie al passo precedente si ha il fattore integrante, il quale viene usato per moltiplicare entrambi i membri dell'equazione differenziale. Quindi:
	
	\begin{equation*}
		\begin{array}{lllll}
			\text{Equazione differenziale}					& \longrightarrow & y^{'} + 2x \: y = x && \forall x \in \mathbb{R}\\
			\text{Equazione diff. per } e^{A\left(x\right)}	& \longrightarrow & \underbrace{e^{x^{2}} \cdot y^{'} + e^{x^{2}} \cdot 2x \: y}_{\left(e^{x^{2}} y\left(x\right)\right)^{'}} = e^{x^{2}} \cdot x && \forall x \in \mathbb{R}
		\end{array}
	\end{equation*}

	\newpage
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 4}}}\newline
	
	\noindent
	Data la \textbf{\emph{forma risolutiva generale}} delle equazioni differenziali lineari del primo ordine:
	
	\begin{equation*}\label{eq}
		y\left(x\right) = e^{-A\left(x\right)} \left(\int e^{A\left(x\right)} f\left(x\right) \: \mathrm{d}x + c\right)
	\end{equation*}
	
	\noindent
	Si sostituiscono i valori noti e si calcola l'integrale:
	
	\begin{equation*}
		\begin{array}{lll}
			\text{Forma risolutiva generale}					& \longrightarrow & \text{(equazione sopra)} \\
			&& \\
			\text{Forma risolutiva generale con valori noti}	& \longrightarrow & e^{x^{2}} \cdot y\left(x\right) = \displaystyle \int x \cdot e^{x^{2}} \: \mathrm{d}x + c \\
			&& \\
																& \hookrightarrow & e^{x^{2}} \cdot y\left(x\right) = \dfrac{e^{x^{2}}}{2} + c \\
			&& \\
			\textbf{Integrale generale (forma finale)}			& \hookrightarrow & y\left(x\right) = \dfrac{1}{2} + c e^{-x^{2}}
		\end{array}
	\end{equation*}

	\noindent
	L'integrale generale ha sempre la $x$ nell'insieme dei reali ovviamente $x \in \mathbb{R}$.
	
	\newpage
	
	\subsubsection[Esempio 2]{\textcolor{Green4}{\textbf{Esempio 2}}}
	
	L'equazione differenziale è la seguente:
	
	\begin{equation*}
		y^{'} - \dfrac{1}{t} y = t^{2}
	\end{equation*}

	\noindent
	Si ricerca l'integrale generale.\newline
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 1}}}\newline
	
	\noindent
	Data la forma generale dell'equazione differenziale lineare del primo ordine:
	
	\begin{equation*}
		y^{'} + a\left(x\right) y = f\left(x\right)
	\end{equation*}
	
	\noindent
	Si evidenziano i termini $a\left(x\right)$ e $f\left(x\right)$ nell'equazione differenziale dell'esercizio:
	
	\begin{equation*}
		\begin{array}{lll}
			y^{'} - \dfrac{1}{t} y = t^{2}	& \longrightarrow & a\left(t\right) = - \dfrac{1}{t} \\
											& \longrightarrow & f\left(t\right) = t^{2}
		\end{array}
	\end{equation*}

	\begin{center}
		\noindent
		\textcolor{Blue3}{\textbf{\underline{Attenzione!}}}
	\end{center}
	Si noti bene che in questo caso la $a\left(t\right)$ è definita nell'insieme: $\left(0, +\infty\right)$. Questo perché la funzione è una frazione e sicuramente non può essere una $0$. Inoltre, dato che \textbf{il problema di Cauchy si definisce solo su intervalli} e nel nostro caso la frazione sarebbe l'unione di due intervalli escluso lo $0$, cioè $\left(-\infty, 0\right) \cup \left(0, +\infty\right)$, è necessario scegliere quale intervallo utilizzare. La decisione viene presa in base ad una specifica dell'esercizio oppure, più frequentemente, in base al punto iniziale fornito dal problema di Cauchy. Infatti, se il punto iniziale fosse maggiore di $0$, si sceglierebbe l'intervallo $\left(0, +\infty\right)$, altrimenti, se fosse negativo, si sceglierebbe l'intervallo $\left(-\infty, 0\right)$.\newline
	
	\noindent
	Al contrario, la funzione $f\left(t\right)$ è definita nell'insieme dei reali $\mathbb{R}$.\newline
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 2}}}\newline
	
	\noindent
	Si calcola la primitiva di $a\left(t\right)$ per costruire il fattore integrante. Quindi:
	
	\begin{equation*}
		a\left(t\right) = - \dfrac{1}{t} \xrightarrow{\text{primitiva}} A\left(t\right) = -\ln t
	\end{equation*}

	\noindent
	E di conseguenza il fattore integrante corrisponde a $e^{-\ln t}$. Con qualche accorgimento è possibile riscrivere il fattore integrante come:
	
	\begin{equation*}
		e^{-\ln t} = \dfrac{1}{t}
	\end{equation*}

	\noindent
	Il meno scompare perché si utilizza la proprietà fondamentale dei logaritmi e si ottiene $t^{-1}$.
	
	\newpage
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 3}}}\newline
	
	\noindent
	Si esegue la moltiplicazione del fattore integrante per l'equazione differenziale:
	
	\begin{equation*}
		\begin{array}{lllll}
			\text{Equazione differenziale}					& \longrightarrow & y^{'} - \dfrac{1}{t} y = t^{2} && \\
			&&&& \\
			\text{Equazione diff. per } e^{A\left(x\right)}	& \longrightarrow & \underbrace{\dfrac{1}{t}y^{'} - \dfrac{1}{t^{2}}}_{\left(\dfrac{1}{t}y\left(t\right)\right)^{'}} = t && \text{con } t \in \left(0, +\infty\right)
		\end{array}
	\end{equation*}

	\noindent
	L'insieme in cui cade $t$ è definito nello stesso modo del passo 1.\newline

	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 4}}}\newline
	
	\noindent
	L'esercizio si conclude calcolando l'integrale generale tramite l'integrale vero e proprio:
	
	\begin{equation*}
		\begin{array}{rll}
			\dfrac{1}{t}y				& = &	\displaystyle\int t \: \mathrm{d}t + c \\
			&& \\
										& = &	\dfrac{1}{t}y = \dfrac{t^{2}}{2} + c \\
			&& \\
			\textbf{Integrale generale}	& = &	y\left(t\right) = \dfrac{1}{2} t^{3} + ct
		\end{array}
	\end{equation*}

	\noindent
	Con $t$ definita nell'insieme del passo 1, cioè $t \in \left(0, +\infty\right)$. Al contrario, la costante $c$ in tutto l'insieme dei reali, quindi $c \in \mathbb{R}$.
	
	\newpage
	
	\subsubsection[Esempio 3]{\textcolor{Green4}{\textbf{Esempio 3}}}
	
	L'equazione differenziale è la seguente:
	
	\begin{equation*}
		x^{'}\left(t\right) + \cot \left(t\right) x\left(t\right) = e^{t}
	\end{equation*}

	Si ricerca l'integrale generale.\newline
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 1}}}\newline
	
	\noindent
	Talvolta le equazioni differenziali hanno variabili diverse dal solito, ma il ragionamento rimane invariato. In questo caso, l'equazione ha la variabile $t$ definita nell'intervallo $t \in \left(0, \pi\right)$. Il motivo è banale:
	
	\begin{equation*}
		\cot\left(t\right) = \dfrac{\cos\left(t\right)}{\sin\left(t\right)}
	\end{equation*}

	\noindent
	Data la forma generale dell'equazione differenziale lineare di primo grado:
	
	\begin{equation*}
		y^{'} + a\left(x\right) y = f\left(x\right)
	\end{equation*}

	\noindent
	Si evidenziano i termini $a\left(t\right)$ e $f\left(t\right)$ dall'equazione:
	
	\begin{equation*}
		\begin{array}{lll}
			x^{'}\left(t\right) + \cot \left(t\right) x\left(t\right) = e^{t}	& \longrightarrow & a\left(t\right) = \cot\left(t\right) \\
			& \longrightarrow & f\left(t\right) = e^{t}
		\end{array}
	\end{equation*}

	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 2}}}\newline
	
	\noindent
	Si calcola la primitiva di $a\left(t\right)$ così da ottenere il fattore integrante. Quindi:
	
	\begin{equation*}
		a\left(t\right) = \cot\left(t\right) \xrightarrow{\text{primitiva}} A\left(t\right) = \int\dfrac{\cos\left(t\right)}{\sin\left(t\right)} \: \mathrm{d}t = \ln \left|sin\left(t\right)\right|
	\end{equation*}
	
	\noindent
	Si sostituisce la primitiva nella definizione del fattore integrante $e^{A\left(t\right)}$ e si ottiene:
	
	\begin{equation*}
		e^{A\left(t\right)} \xrightarrow{\text{sostituzione}} e^{\ln\left|\sin\left(t\right)\right|} = \left|\sin\left(t\right)\right| = \sin\left(t\right)
	\end{equation*}
	
	\noindent
	È possibile portare il $\sin$ fuori dall'esponente grazie ad una delle proprietà dei logaritmi. Inoltre, grazie alla definizione dell'insieme in cui è definita $t$, cioè $t\in\left(0, +\infty\right)$, è possibile anche rimuovere il valore assoluto dato che sarà sempre positivo.\newline
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 3}}}\newline
	
	\noindent
	L'equazione differenziale trovata al passo precedente viene moltiplicata per il fattore integrante:
	
	\begin{equation*}
		\begin{array}{lll}
			\text{Equazione differenziale}					& \longrightarrow & x^{'}\left(t\right) + \cot \left(t\right) x\left(t\right) = e^{t} \\
			&& \\
			\text{Equazione diff. per } e^{A\left(t\right)}	& \longrightarrow & \underbrace{\sin\left(t\right) \cdot x^{'}\left(t\right) + \cos\left(t\right) x\left(t\right)}_{\left(x\left(t\right) \cdot \sin\left(t\right)\right)^{'}} = e^{t} \cdot \sin\left(t\right)
		\end{array}
	\end{equation*}

	\noindent
	Il termine $\cos$ si ricava dall'operazione di moltiplicazione tra cotangente $\cot = \dfrac{\cos\left(t\right)}{\sin\left(t\right)}$ e il seno $\sin\left(t\right)$ che rappresenta il fattore integrante.
	
	\newpage
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 4}}}\newline
	
	\noindent
	Si conclude l'esercizio trovando l'integrale generale:
	
	\begin{equation*}
		\begin{array}{lll}
			x\left(t\right) \cdot \sin\left(t\right) 	& = & \displaystyle\int e^{t} \sin\left(t\right) \: \mathrm{d}t \\
			&& \\
			\text{Integrale per parti}					& = & e^{t} \sin\left(t\right) - \displaystyle\int e^{t} \cos\left(t\right) \: \mathrm{d}t \\
			&& \\
			\text{Si ripete integrazione per parti}		& = & e^{t} \sin\left(t\right) - \left(e^{t} \cos\left(t\right) + \displaystyle\int e^{t} \sin\left(t\right) \: \mathrm{d}t \right) \\
			&& \\
														& = & e^{t} \sin\left(t\right) - e^{t} \cos\left(t\right) - \displaystyle\int e^{t} \sin\left(t\right) \: \mathrm{d}t
		\end{array}
	\end{equation*}

	\noindent
	Dato che l'incognita iniziale era l'integrale $\int e^{t} \sin\left(t\right) \: \mathrm{d}t$ e il risultato che è stato trovato corrisponde a $e^{t} \sin\left(t\right) - e^{t} \cos\left(t\right) - \displaystyle\int e^{t} \sin\left(t\right) \: \mathrm{d}t$, è possibile eguagliare questi due termini per ottenere la soluzione dell'integrale:
	
	\begin{equation*}
		\begin{array}{lll}
			\displaystyle\int e^{t} \sin\left(t\right) \: \mathrm{d}t	& = & e^{t} \sin\left(t\right) - e^{t} \cos\left(t\right) - \displaystyle\int e^{t} \sin\left(t\right) \: \mathrm{d}t \\
			&& \\
			\displaystyle\int e^{t} \sin\left(t\right) \: \mathrm{d}t + \displaystyle\int e^{t} \sin\left(t\right) \: \mathrm{d}t	& = & e^{t} \sin\left(t\right) - e^{t} \cos\left(t\right) \\
			&& \\
			2 \cdot \displaystyle\int e^{t} \sin\left(t\right) \: \mathrm{d}t & = & e^{t} \sin\left(t\right) - e^{t} \cos\left(t\right) \\
			&& \\
			\displaystyle\int e^{t} \sin\left(t\right) \: \mathrm{d}t 	& = & \dfrac{e^{t} \sin\left(t\right) - e^{t} \cos\left(t\right)}{2} \\
			&& \\
			\displaystyle\int e^{t} \sin\left(t\right) \: \mathrm{d}t 	& = & \dfrac{1}{2} \cdot e^{t} \left(\sin\left(t\right) - \cos\left(t\right)\right) + c
		\end{array}
	\end{equation*}

	\noindent
	Per concludere, si riprendere l'equazione generale iniziale e si sostituisce il risultato dell'integrale trovato:
	
	\begin{equation*}
		x\left(t\right) \cdot \sin\left(t\right) = \dfrac{1}{2} \cdot e^{t} \left(\sin\left(t\right) - \cos\left(t\right)\right) + c
	\end{equation*}

	\noindent
	Si esplicita l'incognita e si ottiene l'\textbf{integrale generale}:
	
	\begin{equation*}
		x\left(t\right) = \dfrac{1}{2} \cdot e^{t} \cdot \left(1 - \cot\left(t\right)\right) + \dfrac{c}{\sin\left(t\right)}
	\end{equation*}

	\newpage
	
	\subsection{Operatore differenziale lineare}
	
	Con un punto di vista ancora più generale, si definisce una particolare applicazione che si posiziona tra lo spazio continuo $\mathcal{C}^{1}\left(I\right)$ delle funzioni con derivata continua sull'intervallo $I$ e lo spazio continuo $\mathcal{C}^{0}\left(I\right)$ delle funzioni continue su $I$:
	
	\begin{equation}\label{operatore differenziale lineare di ordine 1}
		\begin{array}{llllll}
			L:	& \mathcal{C}^{1}\left(I\right) & \longrightarrow & \mathcal{C}^{0}\left(I\right) && \\
				& y\left(x\right)				& \longmapsto 	  & y^{'}\left(x\right) + a\left(x\right)y\left(x\right) && \text{con } a\left(x\right) \text{continua su } I
		\end{array}
	\end{equation}

	\noindent
	L'operazione definita e rappresentata dalla lettera $L$ si chiama: \textcolor{Red3}{\textbf{\underline{operatore}}} \textcolor{Red3}{\textbf{\underline{differenziale lineare di ordine 1}}}. Anche per questa operazione vale la \textbf{linearità}.\newline

	\noindent\fbox{%
		\parbox{\textwidth}{%
			\begin{center}
				\textcolor{Red3}{\textbf{\underline{Linearità}}}
			\end{center}
			
			\noindent
			Se $y_{1}\left(x\right), y_{2}\left(x\right) \in \mathcal{C}^{1}\left(I\right)$, allora l'operatore differenziale lineare di ordine 1 viene moltiplicato considerando anche le costanti:
			
			\begin{equation*}
				L\left(\alpha y_{1}\left(x\right) + \beta y_{2}\left(x\right)\right) = \alpha L\left(y_{1}\left(x\right)\right) + \beta L\left(y_{2}\left(x\right)\right) \hspace{2em} \text{con } \alpha, \beta \in \mathbb{R}
			\end{equation*}
			
			\noindent
			Quindi, l'equazione differenziale con la sua forma classica $y^{'}\left(x\right) + a\left(x\right) y\left(x\right) = f\left(x\right)$ con la funzione $f\left(x\right)$ continua sull'intervallo $I$, si può anche riscrivere come:
			
			\begin{equation*}
				L\left(y\left(x\right)\right) = f\left(x\right)
			\end{equation*}
		}%
	}

	\vspace{1.5em}

	\noindent
	Da questa definizione di linearità, la \textcolor{Red3}{\textbf{\underline{soluzione}}} cambia a seconda del tipo:
	
	\begin{itemize}[label=\ding{42}]
		\item \textcolor{Red3}{\textbf{\underline{Omogenea.}}} Allora la funzione $f\left(x\right) = 0$ e di conseguenza l'equazione differenziale $L\left(y\left(x\right)\right) = 0$ ovvero:
		\begin{equation*}
			v = \ker\left(L\right) \text{ è sottospazio vettoriale di } \mathcal{C}^{1}\left(I\right)
		\end{equation*}
		Dove:
		\begin{itemize}[label=-]
			\item $v$ rappresenta l'\textbf{insieme delle soluzioni} dell'omogenea associata;			
			\item $\ker\left(L\right)$ è il \textbf{nucleo} (\emph{kernel}, $\ker$) dell'\textbf{applicazione lineare} $L$;
			\item Il sottospazio vettoriale è chiaro, ma si ricordi che nel caso di equazioni differenziali del primo ordine, la \textbf{dimensione del sottospazio è pari a} $1$.
		\end{itemize}
		L'\textbf{\underline{obbiettivo}} delle soluzioni omogenee è trovare le funzioni di classe $\mathcal{C}^{1}$ che hanno come immagine un vettore nullo.
		
		\item \textcolor{Red3}{\textbf{\underline{Non omogenea.}}} L'insieme delle soluzioni dell'equazione differenziale $L\left(y\left(x\right)\right) = f\left(x\right)$ è definita come:
		\begin{equation*}
			\left\{y_{p}\left(x\right) + y_{v}\left(x\right) : y_{v}\left(x\right) \in \ker\left(L\right)\right\}
		\end{equation*}
	\end{itemize}

	\newpage

	\section{Lezione 04}
	
	\subsection{Equazioni differenziali lineari del secondo ordine}
	
	La forma generale di un'equazione differenziale lineare del \textbf{\underline{secondo ordine}} è la seguente:
	
	\begin{equation*}
		y^{''}\left(x\right) + a\left(x\right)y^{'}\left(x\right) + b\left(x\right)y\left(x\right) = f\left(x\right) \hspace{2em} \text{con } a\left(x\right), b\left(x\right), f\left(x\right) \in \mathcal{C}^{0}\left(I\right)
	\end{equation*}

	\noindent
	Solitamente le equazioni differenziali lineari del secondo ordine vengono associate ad un \textcolor{Red3}{\textbf{\underline{problema di Cauchy}}} date due condizioni iniziali. La forma generale:
	
	\begin{equation*}
		\begin{cases}
			y^{''}\left(x\right) + a\left(x\right)y^{'}\left(x\right) + b\left(x\right)y\left(x\right) = f\left(x\right) & a\left(x\right), b\left(x\right), f\left(x\right) \in \mathcal{C}^{0}\left(I\right) \\
			y\left(x_{0}\right) = y_{0} & x_{0} \in I \\
			y^{'}\left(x_{0}\right) = y_{1}
		\end{cases}
	\end{equation*}

	\noindent
	Anche per questo tipo di equazioni esiste il \textcolor{Red3}{\textbf{\underline{teorema di esistenza e unicità}}}: esiste ed è unica la soluzione al problema di Cauchy definita sull'intervallo $I$. La soluzione è definita in $\mathcal{C}^{2}\left(I\right)$.
	
	\vspace{2em}
	
	\subsubsection{Struttura dell'insieme delle soluzioni di un'equazione differenziale lineare del 2° ordine}
	
	Per l'insieme delle soluzioni si definisce un operatore differenziale lineare:
	
	\begin{equation*}
		\begin{array}{llll}
			L: 	& \mathcal{C}^{2}\left(I\right)	& \longrightarrow & \mathcal{C}^{0}\left(I\right) \\
				& y\left(x\right)				& \longmapsto	  & y^{''}\left(x\right) + a\left(x\right)y^{'}\left(x\right) + b\left(x\right)y\left(x\right) \hspace{2em} \text{con } a\left(x\right), b\left(x\right) \in \mathcal{C}^{0}\left(I\right)
		\end{array}
	\end{equation*}

	\noindent
	L'operatore differenziale lineare $L$ è considerato \dquotes{lineare} poiché:
	
	\begin{equation*}
		L\left(\alpha y_{1}\left(x\right) + f y_{2}\left(x\right)\right) = \alpha L\left(y_{1}\left(x\right)\right) + f L\left(y_{2}\left(x\right)\right) \hspace{2em} \text{con } \forall\alpha, f\in \mathbb{R}
	\end{equation*}

	\noindent
	Ne consegue che l'equazione differenziale e l'operatore differenziale lineare hanno una relazione:
	
	\begin{equation*}
		y^{''}\left(x\right) + a\left(x\right)y^{'}\left(x\right) + b\left(x\right)y\left(x\right) = f\left(x\right) \iff L\left(y\left(x\right)\right) = f\left(x\right)
	\end{equation*}

	\noindent
	\begin{theorem}
		L'insieme $V$ delle soluzioni dell'equazione lineare omogenea:
		
		\begin{equation*}
			y^{''}\left(x\right) + a\left(x\right)y^{'}\left(x\right) + b\left(x\right)y\left(x\right) = 0 \hspace{2em} \text{con } a\left(x\right), b\left(x\right) \in \mathcal{C}^{0}\left(I\right)
		\end{equation*}
	
		\noindent
		È uno spazio vettoriale di dimensione $2$.
	\end{theorem}

	\subsection{Equazioni differenziali lineari del secondo ordine omogenee a coefficienti costanti}
	
	\begin{theorem}
		La funzione $e^{\lambda x} \left(\lambda\in\mathbb{C}\right)$ è la soluzione dell'equazione omogenea $y^{''} + ay^{'} + by = 0$ con $a, b \in \mathbb{R}$ \underline{se e solo se} $\lambda$ è la soluzione dell'equazione algebrica di secondo grado $\lambda^{2} + a\lambda + b = 0$ (quest'ultima chiamata \textcolor{Red3}{\textbf{\underline{equazione caratteristica}}})
	\end{theorem}

	\noindent
	Sia $e^{\lambda x}$ una soluzione. Allora la derivata prima:
	
	\begin{equation*}
		y^{'}\left(x\right) = \lambda e^{\lambda x}
	\end{equation*}

	\noindent
	E la derivata seconda:
	
	\begin{equation*}
		y^{''}\left(x\right) = \lambda^{2} e^{\lambda x}
	\end{equation*}
	
	\noindent
	Sostituendo le derivate nell'equazione differenziale lineare di secondo grado:
	
	\begin{equation*}
		\begin{array}{llll}
			& \lambda^{2}e^{\lambda x} + a\lambda e^{\lambda x} + b e^{\lambda x}	& = & 0 \\
			&&& \\
			\longrightarrow & e^{\lambda x}	\underbrace{\left(\lambda^{2} + a\lambda + b\right)}_{\text{eq. caratteristica}}	& = & 0 \\
			&&& \\
			\text{La } e \text{ è sempre diverso da } 0: & \cancel{e^{\lambda x}} \left(\lambda^{2} + a\lambda + b\right) & = & 0
		\end{array}
	\end{equation*}

	\noindent
	La \textbf{\underline{risoluzione dell'equazione caratteristica}} prevede tre casi:
	
	\begin{enumerate}[label=\Roman*.]
		\item \textcolor{Red3}{\underline{\textbf{Caso} $\Delta > 0$.}} L'equazione caratteristica ha \textbf{due soluzioni reali distinte} $\lambda_{1}, \lambda_{2}$.\newline
		Quindi, $e^{\lambda_{1}x}$ e $e^{\lambda_{2}x}$ sono due soluzioni linearmente indipendenti dell'equazione omogenea.\newline
		Spazio soluzioni rappresenta l'\textbf{\underline{integrale generale}} $v = \left\{c_{1}e^{\lambda_{1}x} + c_{2}e^{\lambda_{2}x} : c_{1}, c_{2} \in \mathbb{R}\right\}$.
		
		\item \textcolor{Red3}{\underline{\textbf{Caso} $\Delta = 0$.}} L'equazione caratteristica ha \textbf{due soluzioni reali coincidenti} $\lambda_{1} = \lambda_{2}$.\newline
		Quindi, $e^{\lambda_{1}x}$ e $e^{\lambda_{2}x}$ sono due soluzioni linearmente indipendenti dell'equazione omogenea.\newline
		L'\textbf{\underline{integrale generale}} è così rappresentato: $y\left(x\right) = c_{1}e^{\lambda_{1}x} + c_{2}e^{\lambda_{2}x}$ con $c_{1}, c_{2} \in \mathbb{R}$.
		
		\item \textcolor{Red3}{\underline{\textbf{Caso} $\Delta < 0$.}} L'equazione caratteristica ha due soluzioni complesse coniugate $\lambda_{1,2} = \alpha \pm i\beta$.\newline
		Quindi, $e^{\left(\alpha + i\beta\right)x}$, $e^{\left(\alpha - i\beta\right)x}$ che grazie ad Eulero è possibile riscriverle:
		\begin{equation*}
			\begin{array}{lll}
				e^{\left(\alpha + i\beta\right)x}	& \longrightarrow & z_{1} = e^{\alpha x}\left(\cos\left(\beta x\right) + i \sin\left(\beta x\right)\right) \\
				&& \\
				e^{\left(\alpha - i\beta\right)x}   & \longrightarrow & z_{2} = e^{\alpha x}\left(\cos\left(\beta x\right) - i \sin\left(\beta x\right)\right)
			\end{array}
		\end{equation*}
		L'\textbf{\underline{integrale generale}} dunque risulta: $y\left(x\right) = c_{1}e^{\alpha x}\cos\left(\beta x\right) + c_{2}e^{\alpha x}\sin\left(\beta x\right)$
	\end{enumerate}

	\newpage

	\subsection{Equazioni differenziali complete omogenee a coefficienti costanti}
	
	L'\textbf{\underline{obbiettivo}} di questo tipo particolare di equazioni consiste nella \emph{ricerca di una soluzione particolare} (definizione spiegata qualche riga più avanti).
	
	La forma generale di un'equazione differenziale completa omogenea a coefficienti costanti è:
	
	\begin{equation*}
		y^{''} + ay^{'} + by = f\left(x\right) \hspace{2em} \text{con } x \in I
	\end{equation*}

	Per risolvere queste equazioni viene utilizzato il \textcolor{Red3}{\textbf{\underline{metodo di somiglianza}}}. Spiegato nel prossimo capitolo, esso consiste nell'individuare una somiglianza tra l'equazione differenziale da calcolare e una già calcolata.\newline
	
	\noindent
	Che cos'è una soluzione particolare? In generale, se la funzione $f\left(x\right)$ è un polinomio di grado $n$ tale che $\left(f\left(x\right) = P_{n}\left(x\right)\right)$ con $b \ne 0$, allora una soluzione particolare è un polinomio di grado $n$:
	
	\begin{equation*}
		y_{P}\left(x\right) = Q_{n}\left(x\right)
	\end{equation*}

	\noindent
	In cui $Q_{n}$ indica un polinomio di grado $n$.
	
	\newpage
	
	\section{Lezione 05}
	
	\subsection{Come trovare una soluzione particolare dell'equazione lineare del 2° ordine a coefficienti costanti}
	
	\begin{center}
		\large
		\textcolor{Red3}{\textbf{\underline{Metodo di somiglianza}}}
	\end{center}

	\noindent
	Se il termine forzante $f\left(x\right)$ ha una forma particolare, allora è possibile trovare una soluzione che abbia una forma \dquotes{simile} alla funzione $f\left(x\right)$:
	
	\begin{itemize}
		\item $f\left(x\right) = p\left(x\right) \cdot e^{\lambda x}$
		
		\item $f\left(x\right) = p\left(x\right) \cdot e^{\lambda x} \cdot \cos\left(\omega x\right)$
		
		\item $f\left(x\right) = p\left(x\right) \cdot e^{\lambda x} \cdot \sin\left(\omega x\right)$
	\end{itemize}

	\noindent
	Con $p$ che rappresenta il polinomio, invece le variabili $\alpha, \omega$ rappresentano numeri reali.
	
	\subsubsection[Esempio 1]{\textcolor{Green4}{Esempio 1}}
	
	Data l'equazione differenziale:
	
	\begin{equation*}
		y^{''} + 5y^{'} + 4y = 3 - 2x
	\end{equation*}
	
	\noindent
	L'obbiettivo è cercare un polinomio che abbia la forma del tipo:
	
	\begin{equation*}
		y_{p}\left(x\right) = a_{0} + a_{1}x
	\end{equation*}

	\noindent
	Nell'equazione differenziale, si nota bene che la parte $3-2x$ rappresenta il polinomio di 1° grado. Adesso si va a sostituire il polinomio $y_{P}$ nell'equazione differenziale ricordando di eseguire eventuali derivate:
	
	\begin{equation*}
		\begin{array}{lll}
			\text{Equazione differenziale} 	& \longrightarrow & y^{''} + 5y^{'} + 4y = 3 - 2x \\
			&& \\
			\text{Derivata seconda}			& \longrightarrow & y^{''} = \left(a_{0}+a_{1}x\right)^{''} = 0 \\
			&& \\
			\text{Derivata prima}			& \longrightarrow & 5y^{'} \\
			&& \\
											& \longrightarrow & 5\cdot\left(a_{0}+a_{1}x\right)^{'} \\
			&& \\
											& \longrightarrow & 5a_{1} \\
			&& \\
			\text{Equazione dopo aver sostituito} & \longrightarrow & 0 + 5a_{1} + 4\left(a_{0}+a_{1}x\right) = 3-2x \\
			&& \\
											& \longrightarrow & 5a_{1} + 4a_{0} + 4a_{1}x = 3 - 2x
		\end{array}
	\end{equation*}

	\noindent
	Con $\forall x \in \mathbb{R}$.

	\newpage

	\noindent
	Per capire se il polinomio è corretto bisogna eseguire un confronto. Quindi, per capire se due polinomi sono uguali, è necessario verificare che siano uguali i coefficienti. Si crea il sistema:
	
	\begin{equation*}
		\begin{cases}
			4a_{1} = -2 \\
			\\
			5a_{1} + 4a_{0} = 3
		\end{cases}
		\longrightarrow
		\begin{cases}
			a_{1} = -\dfrac{1}{2} \\
			\\
			a_{0} = \dfrac{11}{8}
		\end{cases}
	\end{equation*}

	\noindent
	Le equazioni inserite nel sistema corrispondono all'associazione effettuata nell'equazione differenziale, in particolare:
	
	\begin{equation*}
		\textcolor{Green4}{5a_{1}} + \textcolor{Green4}{4a_{0}} + \textcolor{Red3}{4a_{1}x} = \textcolor{Green4}{3} - \textcolor{Red3}{2x}
	\end{equation*}

	\noindent
	Grazie ai colori è adesso comprensibile la costruzione delle equazioni nel sistema:
	
	\begin{itemize}
		\item \textcolor{Green4}{\textbf{Verde}}: $5a_{1} + 4a_{0} = 3$
		\item \textcolor{Red3}{\textbf{Rosso}}: $4a_{1} = -2$
	\end{itemize}

	\noindent
	Dopo aver risolto il sistema, si riscrive il polinomio:
	
	\begin{equation*}
		y_{p} = \dfrac{11}{8} - \dfrac{1}{2}x
	\end{equation*}

	\noindent
	Si ottiene l'equazione caratteristica dall'equazione differenziale:
	
	\begin{equation*}
		y^{''} + 5y^{'} + 4y = 3 - 2x \longrightarrow \lambda^{2} + 5\lambda + 4 = 0
	\end{equation*}

	\noindent
	La quale ha due soluzioni reali distinte (dato che risale immediatamente all'occhio visto che il delta è positivo $\Delta > 0$) $\lambda_{1} = -4, \lambda_{2} = -1$.\newline
	
	\noindent
	Andando a creare l'equazione completa sommando i due fattori integranti e il polinomio:
	
	\begin{equation*}
		y\left(x\right) = c_{1}e^{-4x} + c_{2}e^{-x} + \dfrac{11}{8} - \dfrac{1}{2} x \hspace{2em} \text{con } c_{1}, c_{2} \in \mathbb{R}
	\end{equation*}

	\newpage
	
	\subsubsection[Esempio 2]{\textcolor{Green4}{Esempio 2}}
	
	Questo esempio è diverso dagli altri perché si divide in due casi che presentano ed evidenziano due situazioni differenti. L'idea sarebbe quella di svolgere i passaggi in modo coordinato, come se si stessero facendo nello stesso momento. Questo sarà il compito del lettore, ovvero quello di leggere i due casi nello stesso istante (magari alternando!)
	
	\begin{center}
		\large
		\textcolor{Green4}{\textbf{\underline{Caso A}}}
	\end{center}

	\noindent
	Data l'equazione differenziale:
	
	\begin{equation*}
		y^{''} - 3y^{'} +2y = e^{5x}
	\end{equation*}

	\noindent
	Il polinomio da ottenere è uguale a:
	
	\begin{equation*}
		y_{p}\left(x\right) = c \cdot e^{5x}
	\end{equation*}

	\noindent
	Prima di eseguire le sostituzioni nell'equazione differenziale, si effettuano le derivate:
	
	\begin{equation*}
		\begin{array}{lll}
			y_{p}^{'}\left(x\right)	& = & 5 \cdot c e^{5x} \\
			y_{p}^{''}\left(x\right)& = & 25 \cdot c e^{5x}
		\end{array}
	\end{equation*}

	\noindent
	Si effettua la sostituzione nell'equazione differenziale:
	
	\begin{equation*}
		\begin{array}{lll}
			\text{Equazione differenziale}	& \longrightarrow & y^{''} - 3y^{'} +2y = e^{5x} \\
			&& \\
			\text{Polinomio}				& \longrightarrow & y_{p}\left(x\right) = c \cdot e^{5x} \\
			&& \\
			\text{Derivate del polinomio}	& \longrightarrow & y_{p}^{'}\left(x\right)	= 5 \cdot c e^{5x} \\
			&& \\
											& \longrightarrow & y_{p}^{''}\left(x\right) = 25 \cdot c e^{5x} \\
			&& \\
			\text{Sostituzione}				& \longrightarrow & 25 \cdot c e^{5x} - 3 \left(5 \cdot c e^{5x}\right) + 2 \left(c \cdot e^{5x}\right) = e^{5x} \hspace{2em} \forall x \in \mathbb{R}
		\end{array}
	\end{equation*}

	\noindent
	Si eseguono alcune semplificazioni e si ottiene la variabile $c$:
	
	\begin{equation*}
		\begin{array}{rcc}
			\dfrac{25 \cdot c \cdot \cancel{e^{5x}}}{\cancel{e^{5x}}} - \dfrac{15 \cdot c \cdot \cancel{e^{5x}}}{\cancel{e^{5x}}} + \dfrac{2 \cdot c \cdot \cancel{e^{5x}}}{\cancel{e^{5x}}} & = & \dfrac{\cancel{e^{5x}}}{\cancel{e^{5x}}} \\
			&& \\
			25c - 15c + 2c & = & 1 \\
			&& \\
			c & = & \dfrac{1}{12}
		\end{array}
	\end{equation*}

	\noindent
	Quindi, il polinomio identificato inizialmente diventa:
	
	\begin{equation*}
		y_{p}\left(x\right) = c \cdot e^{5x} \longrightarrow y_{p}\left(x\right) = \dfrac{1}{12} e^{5x}
	\end{equation*}

	\noindent
	L'esercizio si conclude calcolando l'equazione caratteristica:
	
	\begin{equation*}
		\lambda^{2} - 3\lambda + 2 = 0
	\end{equation*}

	\noindent
	Le soluzioni dell'equazione di secondo grado sono due reali e distinte ($\Delta > 0$): $\lambda_{1} = 1, \lambda_{2} = 2$. Andando a sostituire le soluzioni all'interno dell'equazione completa, si ottiene:
	
	\begin{equation*}
		y\left(x\right) = c_{1}e^{x} + c_{2}e^{2x} + \dfrac{1}{12} e^{5x} \hspace{2em} \text{con } c_{1}, c_{2} \in \mathbb{R}
	\end{equation*}

	\noindent
	Si ricorda che l'equazione completa si costruisce sommando i due termini $c$ e le due $e$, le quali avranno come esponente la $x$ e come costante le soluzioni trovate nell'equazione caratteristica. Infine, si somma il polinomio trovato tramite la sostituzione del termine $c$. Quindi, evidenziando i termini:
	
	\begin{equation*}
		y\left(x\right) = \overbrace{c_{1}e^{x}}^{\lambda_{1}} + \underbrace{c_{2}e^{2x}}_{\lambda_{2}} + \overbrace{\dfrac{1}{12} e^{5x}}^{y_{p}}
	\end{equation*}

	\newpage
	
	\begin{center}
		\large
		\textcolor{Green4}{\textbf{\underline{Caso B}}}
	\end{center}
	
	\noindent
	Data l'equazione differenziale, differente dal caso precedente:
	
	\begin{equation*}
		y^{''} - 3y^{'} + 2y = e^{2x}
	\end{equation*}
	
	\noindent
	Il polinomio da ottenere è uguale a:
	
	\begin{equation*}
		y_{p}\left(x\right) = c \cdot e^{2x}
	\end{equation*}
	
	\noindent
	Prima di eseguire le sostituzioni nell'equazione differenziale, si effettuano le derivate:
	
	\begin{equation*}
		\begin{array}{lll}
			y_{p}^{'}\left(x\right)	& = & 2 \cdot c e^{2x} \\
			y_{p}^{''}\left(x\right)& = & 4 \cdot c e^{2x}
		\end{array}
	\end{equation*}
	
	\noindent
	Si effettua la sostituzione nell'equazione differenziale:
	
	\begin{equation*}
		\begin{array}{lll}
			\text{Equazione differenziale}	& \longrightarrow & y^{''} - 3y^{'} +2y = e^{2x} \\
			&& \\
			\text{Polinomio}				& \longrightarrow & y_{p}\left(x\right) = c \cdot e^{2x} \\
			&& \\
			\text{Derivate del polinomio}	& \longrightarrow & y_{p}^{'}\left(x\right)	= 2 \cdot c e^{2x} \\
			&& \\
			& \longrightarrow & y_{p}^{''}\left(x\right) = 4 \cdot c e^{2x} \\
			&& \\
			\text{Sostituzione}				& \longrightarrow & 4 \cdot c e^{2x} - 3 \left(2 \cdot c e^{2x}\right) + 2 \left(c \cdot e^{2x}\right) = e^{2x} \hspace{2em} \forall x \in \mathbb{R}
		\end{array}
	\end{equation*}
	
	\noindent
	Qui c'è la differenza sostanziale rispetto all'esercizio precedente. Provando a semplificare l'equazione differenziale tramite la variabile $e^{2x}$, si ottiene l'uguaglianza $0 = 1$:
	
	\begin{equation*}
		\dfrac{4 \cdot c \cdot \cancel{e^{2x}}}{\cancel{e^{2x}}} - \dfrac{3 \left(2 \cdot c \cdot \cancel{e^{2x}}\right)}{\cancel{e^{2x}}} + \dfrac{2 \left(c \cdot \cancel{e^{2x}}\right)}{\cancel{e^{2x}}} = \dfrac{\cancel{e^{2x}}}{\cancel{e^{2x}}}
	\end{equation*}

	\noindent
	Questo accade perché il valore $2$, il quale era l'unico termine diverso rispetto al caso A, è una soluzione dell'equazione caratteristica. Quindi, si cambia il polinomio applicando una piccola variazione:
	
	\begin{equation*}
		y_{p}\left(x\right) = c \cdot x \cdot e^{2x}
	\end{equation*}

	\noindent
	Si rieseguono i procedimenti classici:
	
	\begin{equation*}
		\begin{array}{lll}
			\text{Equazione differenziale}	& \longrightarrow & y^{''} - 3y^{'} +2y = e^{2x} \\
			&& \\
			\text{Polinomio}				& \longrightarrow & y_{p}\left(x\right) = c \cdot x \cdot e^{2x} \\
			&& \\
			\text{Derivate del polinomio}	& \longrightarrow & y_{p}^{'}\left(x\right)	= ce^{2x} + cx \cdot 2e^{2x} = ce^{2x}\left(1 + 2x\right) \\
			&& \\
			& \longrightarrow & y_{p}^{''}\left(x\right) = 2ce^{2x} \cdot \left(1 + 2x\right) + ce^{2x} \cdot 2 = 2ce^{2x}\left(2 + 2x\right) \\
			&& \\
			\text{Sostituzione}				& \longrightarrow & 2ce^{2x}\left(2 + 2x\right) - 3 \left(ce^{2x}\left(1 + 2x\right)\right) + 2\left(ce^{2x}\right) = e^{2x} \hspace{2em} \forall x \in \mathbb{R}
		\end{array}
	\end{equation*}

	\noindent
	Eseguendo le classe semplificazioni, che vengono omesse, si ottiene la costante uguale a $1$, $c = 1$. Si conclude l'esercizio andando a costruire il polinomio particolare:
	
	\begin{equation*}
		y_{p}\left(x\right) = x e^{2x}
	\end{equation*}

	\noindent
	Adesso si dovrebbe calcolare l'equazione caratteristica, trovare le sue soluzioni e andare a costruire l'equazione completa. Tuttavia, i passaggi sono identici al caso A dato che le due equazioni differenziali hanno i due termini a sinistra identici.
	
	\newpage
	
	\subsubsection[Esempio 3]{\textcolor{Green4}{Esempio 3}}
	
	Data l'equazione differenziale:
	
	\begin{equation*}
		y^{''} + y = \sin\left(2x\right)
	\end{equation*}

	Si calcola l'equazione particolare. Il polinomio simile è il seguente:
	
	\begin{equation*}
		y_{p}\left(x\right) = c_{1}\cos\left(2x\right) + c_{2}\sin\left(2x\right)
	\end{equation*}

	\noindent
	Si calcolano le derivate:
	
	\begin{equation*}
		\begin{array}{lll}
			y_{p}^{'}\left(x\right)	& = & -2c_{1}\sin\left(2x\right) + 2c_{2}\cos\left(2x\right) \\
			y_{p}^{''}\left(x\right)& = & -4c_{1}\cos\left(2x\right) - 4c_{2}\sin\left(2x\right)
		\end{array}
	\end{equation*}

	\noindent
	Nell'equazione differenziale si sostituiscono le derivate:
	
	\begin{equation*}
		-4c_{1}\cos\left(2x\right) - 3c_{2}\sin\left(2x\right) + c_{1}\cos\left(2x\right) + c_{2}\sin\left(2x\right) = \sin\left(2x\right)
	\end{equation*}

	\noindent
	Si eseguono le semplificazioni e si ottiene l'equazione:
	
	\begin{equation*}
		-3c_{1}\cos\left(2x\right) - 3c_{2}\sin\left(2x\right) = \sin\left(2x\right)
	\end{equation*}

	\noindent
	Le due costanti si ottengono inserendo i valori nel sistema:
	
	\begin{equation*}
		\begin{cases}
			-3c_{1} = 0 \\
			-3c_{2} = 1
		\end{cases}
		\longrightarrow
		\begin{cases}
			c_{1} = 0 \\
			c_{2} = -\dfrac{1}{3}
		\end{cases}
	\end{equation*}

	\noindent
	Si sostituiscono i valori trovati nel polinomio iniziale:
	
	\begin{equation*}
		y_{p}\left(x\right) = c_{1}\cos\left(2x\right) + c_{2}\sin\left(2x\right) \longrightarrow y_{p}\left(x\right) = -\dfrac{1}{3}\sin\left(2x\right)
	\end{equation*}

	\noindent\fbox{%
		\parbox{\textwidth}{%
			\textcolor{Red3}{\textbf{\underline{Attenzione!}}}\newline
			
			\noindent
			Nel caso in cui l'equazione differenziale fosse stata $y^{''} + y = \sin\left(x\right)$, la risoluzione avrebbe avuto gli stessi problemi dell'esempio 2, caso B. La situazione sarebbe stata risolto con una piccola variazione, ovvero aggiungendo una $x$ a $y_{p}$:
			
			\begin{equation*}
				\begin{array}{llll}
					\textcolor{Red3}{\textbf{OLD:}} & y_{p} & = & c_{1}\cos\left(x\right) + c_{2}\sin\left(x\right) \\
					\textcolor{Green4}{\textbf{NEW:}} & y_{p} & = & x \cdot \left(c_{1}\cos\left(x\right) + c_{2}\sin\left(x\right)\right)
				\end{array}
			\end{equation*}
		}%
	}

	\newpage
	
	\subsection{Sintesi}
	
	In questo capitolo è stato ampiamente spiegato come trovare una soluzione particolare per un'equazione differenziale lineare del 2° ordine a coefficienti costanti. Esistono alcune forme particolari che sono utili per trovare la soluzione (l'elenco è stato fatto all'inizio del capitolo). Il metodo di somiglianza funzione perché si suppone che la soluzione abbia una forma \dquotes{simile} alle forme particolari introdotte.
	
	Il primo esempio ha spiegato dettagliatamente i passaggi da seguire per risolvere questo tipo di esercizi. Il secondo ha introdotto un problema che è possibile che si verifichi, ovvero quello di trovare una soluzione dell'equazione caratteristica prima del previsto (caso B). Infine, il terzo esempio ha concluso la spiegazione mostrando un esercizio un leggermente più complesso.\newline
	
	\noindent
	Sia:
	
	\begin{equation*}
		f\left(x\right) = p\left(x\right) e^{\alpha x}
	\end{equation*}
	
	\noindent
	La funzione particolare, allora si costruisce l'equazione particolare in questo modo:
	
	\begin{equation*}
		y_{p}\left(x\right) = Q\left(x\right) x^{m} e^{\alpha x}
	\end{equation*}

	\noindent
	In cui la $Q$ rappresenta la $p$ nella funzione $f$. Invece, la variabile $m$ è la molteplicità di $\alpha$ come radice dell'equazione caratteristica e infatti è definita come $m\in\left\{0,1,2\right\}$.\newline
	
	\noindent
	Un'altra forma della funzione è:
	
	\begin{equation*}
		f\left(x\right) = p\left(x\right) e^{\alpha x} \cdot \underbrace{\cos\left(\omega x\right)}_{\text{oppure } \sin\left(\omega x\right)}
	\end{equation*}
	
	\noindent
	Allora la funzione particolare si costruisce in questo modo:
	
	\begin{equation*}
		y_{p}\left(x\right) = e^{\alpha x} \cdot x^{m} \left(Q_{1}\left(x\right)\cos\left(\omega x\right) + Q_{2}\left(x\right)\sin\left(\omega x\right)\right)
	\end{equation*}

	\noindent
	Con $m \ne 0$ se $\alpha + i \omega$ è la soluzione dell'equazione caratteristica.
	
	\newpage
	
	\section{Lezione 06}
	
	\subsection{Come trovare una soluzione particolare dell'equazione differenziale lineare del 2° ordine a coefficienti costanti}
	
	Oltre al metodo di somiglianza introdotto nel capitolo precedente, esiste un altro metodo chiamato \textbf{metodo di variazione delle costanti}.
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Metodo di variazione delle costanti}}}\newline
	
	\noindent
	Data l'equazione differenziale di secondo grado:
	
	\begin{equation*}
		y^{''} + ay^{'} + by = f\left(x\right)
	\end{equation*}

	\noindent
	È conosciuto l'integrale generale dell'omogenea associata $y_{v}\left(x\right) = c_{1}y_{1}\left(x\right) + c_{2}y_{2}\left(x\right)$ dove $y_{1}\left(x\right)$ e $y_{2}\left(x\right)$ sono soluzioni indipendenti su $I$.
	
	\noindent
	L'\textcolor{Red3}{\textbf{\underline{obbiettivo}}} è cercare una soluzione particolare dell'equazione completa nella forma:
	
	\begin{equation*}
		y_{p}\left(x\right) = c_{1}\left(x\right)y_{1}\left(x\right) + c_{2}\left(x\right)y_{2}\left(x\right)
	\end{equation*}

	\noindent
	Con $c_{1}, c_{2}$ sono variazioni delle costanti.\newline
	
	\noindent
	A \textbf{differenza del metodo di somiglianza}, le costanti qui sono \emph{funzioni}. Come nel metodo di somiglianza, l'equazione particolare si sostituisce nell'equazione completa calcolando le derivate (la seconda si omette perché sarà introdotta tra poco):
	
	\begin{equation*}
		\begin{array}{lll}
			y_{p}\left(x\right)		& = & c_{1}\left(x\right)y_{1}\left(x\right) + c_{2}\left(x\right)y_{2}\left(x\right) \\
			&& \\
			y_{p}^{'}\left(x\right) & = & c_{1}^{'}\left(x\right)y_{1}\left(x\right) + c_{1}\left(x\right)y_{1}^{'}\left(x\right) + c_{2}^{'}\left(x\right)y_{2}\left(x\right) + c_{2}\left(x\right)y_{2}^{'}\left(x\right)
		\end{array}
	\end{equation*}

	\noindent
	Per semplificare l'espressione, si esegue una scelta di comodo: $c_{1}^{'}\left(x\right)y_{1}\left(x\right) + c_{2}^{'}\left(x\right)y_{2}\left(x\right) = 0$ con $\forall x \in I$. Quindi, la derivata prima e seconda si \emph{riscrivono}:
	
	\begin{equation*}
		\begin{array}{lll}
			y_{p}^{'}\left(x\right)	& = & c_{1}\left(x\right)y_{1}^{'}\left(x\right) + c_{2}\left(x\right)y_{2}^{'}\left(x\right) \\
			&& \\
			y_{p}^{''}\left(x\right)& = & c_{1}^{'}\left(x\right)y_{1}^{'}\left(x\right) + c_{1}\left(x\right)y_{1}^{''}\left(x\right) + c_{2}^{'}\left(x\right)y_{2}^{'}\left(x\right) + c_{2}\left(x\right)y_{2}^{''}\left(x\right)
		\end{array}
	\end{equation*}

	\noindent
	Sostituendo e raggruppando le derivate nell'equazione completa, si ha:
	
	\begin{equation*}
		c_{1}\underbrace{\left( y_{1}^{''} + ay_{1}^{'} + by_{1} \right)}_{*} + c_{2}\underbrace{\left( y_{2}^{''} + ay_{2}^{'} + by_{2} \right)}_{*} + c_{1}^{'}y_{1}^{'} + c_{2}^{'}y_{2}^{'}
	\end{equation*}
	
	\noindent
	In cui le due equazioni tra parentesi contrassegnate con l'asterisco sono uguali a zero poiché vengono trattate solamente equazioni omogenee, cioè uguale a zero. Quindi, rimuovendo i termini nulli dall'equazione e mettendo a sistema i rimanenti:
	
	\begin{equation*}
		\cancel{c_{1}\left( y_{1}^{''} + ay_{1}^{'} + by_{1} \right)} + \cancel{c_{2}\left( y_{2}^{''} + ay_{2}^{'} + by_{2} \right)} + c_{1}^{'}y_{1}^{'} + c_{2}^{'}y_{2}^{'} \longrightarrow
		\begin{cases}
			c_{1}^{'}y_{1} + c_{2}^{'}y_{2} = 0 \\
			c_{1}^{'}y_{1}^{'} + c_{2}^{'}y_{2}^{'} = f\left(x\right)
		\end{cases}
	\end{equation*}

	\noindent
	Grazie al corso di algebra lineare è noto come scrivere un sistema in \textbf{forma matriciale}. In particolare si creano tre matrici, di cui la prima viene chiamata \textcolor{Red3}{\textbf{\underline{matrice wronskiana}}}:
	
	\begin{equation*}
		\begin{cases}
			c_{1}^{'}y_{1} + c_{2}^{'}y_{2} = 0 \\
			\\
			c_{1}^{'}y_{1}^{'} + c_{2}^{'}y_{2}^{'} = f\left(x\right)
		\end{cases}
		\longrightarrow
		\begin{bmatrix}
			y_{1} 		& y_{2} 	\\
						&			\\
			y_{1}^{'}	& y_{2}^{'}
		\end{bmatrix}
		\cdot
		\begin{bmatrix}
			c_{1}^{'} \\
			\\
			c_{2}^{'}
		\end{bmatrix}
		=
		\begin{bmatrix}
			0 \\
			\\
			f
		\end{bmatrix}
	\end{equation*}
	
	\noindent
	La \textbf{\underline{matrice wronskiana}} è associata a $y_{1}$ e $y_{2}$. Inoltre, è sempre invertibile $\forall x \in I$ cioè il \emph{determinante è diverso da zero}: $\det W\left(x\right) \ne 0$ $\forall x \in I$.\newline
	
	\noindent
	Grazie a questa forma matriciale, si calcolano le due variabili $c_{1}^{'}, c_{2}^{'}$:
	
	\begin{gather*}
		c_{1}^{'} = \dfrac{
		\begin{vmatrix}
			0	&	y_{2} 		\\
			f	& 	y_{2}^{'}
		\end{vmatrix}
		}{y_{1} \cdot y_{2}^{'} - y_{1}^{'} \cdot y_{2}}
		=
		- \dfrac{f \cdot y_{2}}{y_{1} \cdot y_{2}^{'} - y_{1}^{'} \cdot y_{2}}
		\\
		\\
		c_{1}^{'} = \dfrac{
		\begin{vmatrix}
			y_{1}		&	0	\\
			y_{1}^{'}	& 	f
		\end{vmatrix}
		}{y_{1} \cdot y_{2}^{'} - y_{1}^{'} \cdot y_{2}}
		=
		+ \dfrac{f \cdot y_{1}}{y_{1} \cdot y_{2}^{'} - y_{1}^{'} \cdot y_{2}}
	\end{gather*}

	\noindent
	Con $c_{1}^{'}$ e $c_{2}^{'}$ che sono continue nell'intervallo $I$ e quindi integrabili.
	
	\newpage
	
	\subsubsection[Esempio]{\textcolor{Green4}{Esempio}}
	
	Si risolva il seguente problema di Cauchy:
	
	\begin{equation*}
		\begin{cases}
			y'' + y = \sin\left(x\right) \\
			y\left(0\right) = 0 \\
			y'\left(0\right) = 0
		\end{cases}
	\end{equation*}

	\noindent
	Si elencano di seguito i passaggi per risolvere l'esercizio usando il metodo di variazione delle costanti (paragrafo precedente).\newline
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 1}}}\newline
	
	\noindent
	Si ricava l'equazione caratteristica dall'equazione differenziale data:
	
	\begin{equation*}
		y'' + y = \sin\left(x\right) \longrightarrow \lambda^{2} + 1 = 0
	\end{equation*}

	\noindent
	Le soluzioni trovate sono due complesse coniugate: $\lambda_{1} = i, \lambda_{2} = -i$.\newline
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 2}}}\newline
	
	\noindent
	Si scrive l'integrale generale dell'equazione differenziale omogenea associata, dato che è sicuro che esiste grazie alla matrice wronskiana: $y_{v}\left(x\right) = c_{1}\cos\left(x\right) + c_{2}\sin\left(x\right)$.\newline
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 3}}}\newline
	
	\noindent
	Adesso è possibile costruire la matrice wronskiana:
	
	\begin{equation*}
		W\left(x\right) = \begin{bmatrix}
			\phantom{-}\cos\left(x\right)	&	\sin\left(x\right)	\\
			-\sin\left(x\right)				&	\cos\left(x\right)	
		\end{bmatrix}
		\text{ con } \det W\left(x\right) = \cos^{2}\left(x\right) + \sin^{2}\left(x\right) = 1 \hspace{2em} \forall x \in \mathbb{R}
	\end{equation*}
	
	\noindent
	In cui i valori nella seconda riga sono le derivate della prima.\newline
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 4}}}\newline
	
	\noindent
	Si scrive l'intero sistema utilizzando le matrici:
	
	\begin{equation*}
		\begin{bmatrix}
			\phantom{-}\cos\left(x\right)	&	\sin\left(x\right) \\
			-\sin\left(x\right)				&	\cos\left(x\right)
		\end{bmatrix}
		\cdot
		\begin{bmatrix}
			c'_{1}\left(x\right) \\
			\\
			c'_{2}\left(x\right)
		\end{bmatrix}
		=
		\begin{bmatrix}
			0 \\
			\\
			\sin\left(x\right)
		\end{bmatrix}
	\end{equation*}

	\noindent
	E si calcola la matrice inversa:
	
	\begin{equation*}
		\begin{bmatrix}
			c'_{1}\left(x\right) \\
			\\
			c'_{2}\left(x\right)
		\end{bmatrix}
		=
		\underbrace{
			\begin{bmatrix}
				\cos\left(x\right)	&	-\sin\left(x\right) \\
				\sin\left(x\right)	&	\phantom{-}\cos\left(x\right)
			\end{bmatrix}
		}_{W^{-1}\left(x\right)}
		\cdot
		\begin{bmatrix}
			0 \\
			\\
			\sin\left(x\right)
		\end{bmatrix}
		=
		\begin{bmatrix}
			-\sin^{2}\left(x\right) \\
			\\
			\sin\left(x\right)\cos\left(x\right)
		\end{bmatrix}
	\end{equation*}

	\noindent
	Le costanti sono evidenti, ovvero:
	
	\begin{equation*}
		\begin{array}{lll}
			c'_{1}\left(x\right)	& = & -\sin^{2}\left(x\right) \\
			c'_{2}\left(x\right)	& = & \sin\left(x\right)\cos\left(x\right)
		\end{array}
	\end{equation*}

	\noindent
	\textcolor{Red3}{\textbf{\underline{Passo 5}}}\newline
	
	\noindent
	L'ultimo passaggio è calcolare l'integrale delle costanti trovate:
	
	\begin{equation*}
		\begin{array}{lllll}
			c_{1}\left(x\right) & = & \displaystyle-\int\sin^{2}\left(x\right)\:\mathrm{d}x & = & -\dfrac{1}{2}x + \dfrac{1}{4}\sin\left(2x\right) + c \\
			&&&& \\
			c_{2}\left(x\right) & = & \displaystyle\phantom{-}\int\sin\left(x\right)\cos\left(x\right)\:\mathrm{d}x & = & -\dfrac{1}{4}\cos\left(2x\right) + c
		\end{array}
	\end{equation*}

	\noindent
	Andando a sostituire le soluzioni trovate nell'equazione particolare $y_{p}$ si trovano i valori:
	
	\begin{equation*}
		\begin{array}{lll}
			y_{p}\left(x\right) & = & c_{1}\left(x\right)\cos\left(x\right) + c_{2}\left(x\right)\sin\left(x\right) \\
			&& \\
								& = & \left(- \dfrac{1}{2}x + \dfrac{1}{4} \sin\left(2x\right)\right)\cos\left(x\right) - \dfrac{1}{4} \cos\left(2x\right)\sin\left(x\right)
		\end{array}
	\end{equation*}
	
	\newpage
	
	\section{Lezione 07}
	
	\subsection[Spazio euclideo ${n}$-dimensionale]{Spazio euclideo $\boldsymbol{n}$-dimensionale}
	
	L'insieme in cui si lavora è il seguente:
	
	\begin{equation*}
		\mathbb{R}^{n} = \left\{x = \left(x_{1}, x_{2}, ..., x_{n}\right) : x_{i} \in \mathbb{R}\right\} \hspace{2em} \text{con } i \in \mathbb{N}, 1 \le i \le n
	\end{equation*}

	\noindent
	Che identifica uno \textbf{\underline{spazio vettoriale normato}}.\newline
	
	\noindent
	\textcolor{Red3}{\textbf{\underline{Ripasso - Spazio vettoriale:}}} nello spazio vettoriale esistono due operazioni:
	
	\begin{itemize}
		\item \textbf{Somma:} $\left(x_{1}, ..., x_{n}\right) + \left(y_{1}, ..., y_{n}\right) = \left(x_{1} + y_{1}, x_{2} + y_{2}, ..., x_{n} + y_{n}\right)$ con $x,y \in \mathbb{R}^{n}$
		
		\item \textbf{Prodotto per uno scalare:} $\lambda \in \mathbb{R}, x = \left(x_{1}, ..., x_{n}\right) \in \mathbb{R}^{n} : \lambda x = \left(\lambda x_{1}, \lambda x_{2}, ..., \lambda x_{n}\right)$
	\end{itemize}
	\:\newline

	\noindent
	\textcolor{Red3}{\textbf{\underline{Ripasso - Normato:}}} lo spazio vettoriale è normato quando è dotato di una norma, ovvero di una funzione particolare in $\mathbb{R}^{n}$: \textbf{dominio} $\Big||\cdot|\Big| : \mathbb{R}^{n} \longrightarrow \mathbb{R}$, ovvero un vettore restituisce un numero reale:
	
	\begin{equation*}
		x \longmapsto \Big||x|\Big| \text{ che sarebbe la norma di } x
	\end{equation*}

	\noindent
	Le sue caratteristiche sono:
	
	\begin{itemize}
		\item $\Big|x\Big| \ge 0$, la norma di x è maggiore uguale a zero per ogni $x \in \mathbb{R}^{n}$; inoltre la norma di $x$ è zero $\Big||x|\Big| = 0$ (norma che rappresenta un numero reale) se e solo se $x = 0$ (con $x$ che è un vettore in $\mathbb{R}^{n}$).
		
		\item $\Big||\lambda x|\Big| = |\lambda| \Big||x|\Big|$, ovvero i vettori sono uguali ad un numero reale per un vettore. Questo vale per ogni $\lambda \in \mathbb{R}$ e per ogni $x \in \mathbb{R}^{n}$.
		
		\item $\Big||x+y|\Big| \le \Big||x|\Big| + \Big||y|\Big|$ per ogni $x,y \in \mathbb{R}^{n}$. Caratteristica chiamata \textcolor{Red3}{\textbf{\underline{disuguaglianza triangolare}}}.
	\end{itemize}

	\newpage
	
	\subsection{Norma euclidea}
	
	Si definisce la Norma Euclidea una norma di uno spazio vettoriale, quindi quello che è già stato affrontato nel paragrafo precedente:
	
	\begin{equation}\label{Norma euclidea}
		\Big||x|\Big|_{2} = \sqrt{\sum_{i = 1}^{n} x_{i}^{2}} = \sqrt{x \cdot x}
	\end{equation}
	
	\noindent
	In cui la moltiplicazione rappresenta il prodotto scalare nell'insieme $\mathbb{R}^{n}$.
	
	\subsection{Disuguaglianza (triangolare) di Cauchy-Schwarz}
	
	Per ogni $x, y \in \mathbb{R}^{n}$ si ha:
	
	\begin{equation}\label{disuguaglianza triangolare di cauchy-schwarz}
		|x \cdot y| \le \Big||x|\Big| \cdot \Big||y|\Big|
	\end{equation}

	\noindent
	In cui il termine di sinistra indica il prodotto scalare assoluto tra due vettori, mentre il termine di destra indica il prodotto nell'insieme $\mathbb{R}$ di norme tra due vettori.
	
	\subsection{Distanza euclidea}
	
	Introdotta dalla norma seconda, si definisce la distanza euclidea come:
	
	\begin{equation}\label{distanza euclidea}
		\mathrm{d}\left(x,y\right) = \Big||x-y|\Big| = \sqrt{\left(x_{1}-y_{1}\right)^{2} + \left(x_{2}-y_{2}\right)^{2} + \cdots + \left(x_{1}-y_{1}\right)^{2}} \hspace{2em} \text{con } x,y\in\mathbb{R}^{n}
	\end{equation}

	\noindent
	Come si vede sotto la radice, essa non è altro che la \emph{differenza delle varie componenti dei vettori}.

	\noindent
	Per completezza si introduce anche la definizione di \textbf{\underline{distanza di Manhattan}}:
	
	\begin{equation}\label{distanza di Manhattan}
		\mathrm{d}_{1}\left(x,y\right) = \Big||x-y|\Big|_{1} = \sum_{i = 1}^{n} |x_{i} - y_{i}|
	\end{equation}

	\noindent
	Inoltre, si definisce \textbf{\underline{metrica}} una funzione $\mathrm{d}$ in $\mathbb{R}^{n}$:
	
	\begin{equation}\label{metrica}
		\begin{array}{lll}
			\mathbb{R}^{n} \times \mathbb{R}^{n} & \longrightarrow & \mathbb{R} \\
			&& \\
			\left(x,y\right)					 & \longmapsto	   & \mathrm{d}\left(x,y\right)
		\end{array}
	\end{equation}

	\noindent
	Con le seguenti \textbf{\emph{proprietà}}:
	
	\begin{itemize}
		\item \textbf{Non negatività:} $\mathrm{d}\left(x,y\right) \ge 0$ per ogni $x,y$. Inoltre, $\mathrm{d}\left(x,y\right) = 0$ se e solo se $x = y$ (la distanza tra $x$ e $y$ non è \underline{mai} nulla).
		
		\item \textbf{Simmetria:} $\mathrm{d}\left(x,y\right) = \mathrm{d}\left(y,x\right)$ per ogni $x,y\in\mathbb{R}^{n}$ (la distanza deve essere una funzione simmetrica).
		
		\item \textbf{Disuguaglianza triangolare:} $\mathrm{d}\left(x,y\right) + \mathrm{d}\left(y,z\right) \ge \mathrm{d}\left(x,z\right)$ per ogni $x,y,z \in \mathbb{R}^{n}$ (disuguaglianza triangolare).
	\end{itemize}

	\newpage
	
	\subsection{Topologia in $\mathbb{R}^{n}$}
	
	Si definisce la \textbf{palla aperta} di centro $\bar{x}\in\mathbb{R}^{n}$ e raggio maggiore di zero $r > 0$, cioè la distanza è minore del raggio $r$. La funzione è definita in questo modo:
	
	\begin{equation*}
		B_{r}\left(\bar{x}\right) = \left\{x \in \mathbb{R}^{n} : \mathrm{d}\left(x,\bar{x}\right) < r\right\}
	\end{equation*}

	\noindent
	Un esempio di palla aperta con $n = 2$:
	
	\begin{figure}[!htp]
		\centering
		\includegraphics[width=0.6\textwidth]{img/palla_aperta.pdf}
		\caption{Palla aperta di coordinate $\left(3,2\right)$ con $n = 2$.}
	\end{figure}

	\noindent
	Con $n = 1$ la dimensione è monodimensionale:
	
	\begin{figure}[!htp]
		\centering
		\includegraphics[width=0.5\textwidth]{img/monodimensionale.pdf}
		\caption{Retta monodimensionale con $n = 1$.}
	\end{figure}

	\noindent
	Con $n = 3$ la dimensione è tridimensionale:
	
	\begin{figure}[!htp]
		\centering
		\includegraphics[width=0.5\textwidth]{img/tridimensionale.pdf}
		\caption{Sfera in $\mathbb{R}$ con $n = 3$ senza bordo, cioè senza superficie.}
	\end{figure}

	\newpage
	
	\noindent\fcolorbox{Red3}{white}{%
		\parbox{\textwidth}{%
			\textcolor{Red3}{\textbf{\underline{Definizione}}}\newline
			
			\noindent
			Si definisce $U$ come il sottoinsieme di $\mathbb{R}^{ n}$, cioè $U \subseteq \mathbb{R}^{n}$ che è intorno di $\bar{x} \in \mathbb{R}^{n}$ se esiste $\exists r > 0$ tale che la palla è centrata: $B_{r}\left(\bar{x}\right) \subseteq U$
		}%
	}
	\:\newline

	\noindent
	\textcolor{Green4}{\textbf{Per esempio}}, data la seguente figura, si determini se:
	
	\begin{enumerate}
		\item $U$ è intorno di $v = \left(1,1\right)$?
		
		\item $U$ è intorno di $v = \left(3,0\right)$?
	\end{enumerate}

	\begin{figure}[!htp]
		\centering
		\includegraphics[width=0.5\textwidth]{img/esempio_topologia.pdf}
	\end{figure}

	\noindent
	Nella figura si rappresentano i punti di coordinate $\left(1,1\right)$ e $\left(3,0\right)$.\newline
	
	\noindent
	\textcolor{Green4}{\textbf{\underline{Risposta - Domanda 1}}}\newline
	
	\noindent
	$U$ è intorno di $v = \left(1,1\right)$ perché $B_{\frac{1}{2}}\left(v\right) \subseteq U$. La funzione $B$ ha come pedice $\frac{1}{2}$ poiché questa frazione rappresenta il raggio e infatti è centrata $\left(\frac{1}{2} \cdot 2 = 1\right)$.\newline
	
	\noindent
	\textcolor{Green4}{\textbf{\underline{Risposta - Domanda 2}}}\newline
	
	\noindent
	$U$ \emph{non} è intorno di $v = \left(3,0\right)$ poiché sicuramente almeno un punto è fuori da $U$.
	
	\newpage
	
	\noindent\fcolorbox{Red3}{white}{%
		\parbox{\textwidth}{%
			\textcolor{Red3}{\textbf{\underline{Definizione}}}\newline
			
			\noindent
			Dato un insieme $A$ si definiscono:
			
			\begin{itemize}
				\item \textbf{Punto interno}: tutti i punti dell'intorno sono dentro $A$.
				 
				\item \textbf{Punto di frontiera}: alcuni punti sono dentro e altri fuori.
				
				\item \textbf{Punto esterno}: tutti i punti sono esterni ad $A$.
			\end{itemize}
		}%
	}

	\begin{figure}[!htp]
		\centering
		\includegraphics[width=0.7\textwidth]{img/punti.pdf}
		\caption{Punto esterno, interno e di frontiera.}
	\end{figure}

	\newpage
	
	\section{Lezione 08}
\end{document}